{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##sympy setup\n",
    "!git clone https://github.com/sympy/sympy.git\n",
    "import os\n",
    "os.chdir('sympy/')\n",
    "os.getcwdb()\n",
    "!python -m pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def equation_solver(text):\n",
    "\n",
    "  matches = re.findall(r'\\[(.*?)\\]', text)\n",
    "  answer=text.split(\"The answer is \")[-1].replace(\".\",\"\")\n",
    "  answer=symbols(answer)\n",
    "  list_eq=[]\n",
    "  for i in matches:\n",
    "    eq=sympify(\"Eq(\" + i.replace(\"=\", \",\") + \")\")\n",
    "    list_eq.append(eq)\n",
    "  result =solve(list_eq)\n",
    "\n",
    "  if(answer in result.keys()):\n",
    "    return int(result[answer])\n",
    "  else:\n",
    "    return list(result.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle('mistral1_math_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row=df.iloc[0].to_dict()\n",
    "text=row['sft_response']\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equation_solver(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvable=[]\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "  row=df.iloc[i].to_dict()\n",
    "  text=row['sft_response']\n",
    "  try:\n",
    "    ans=equation_solver(text)\n",
    "    row[\"solved_answer\"]=ans\n",
    "    solvable.append(row)\n",
    "  except:\n",
    "    ans='not solvable'\n",
    "    print(ans,row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wikipedia\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "#from datasets import load_dataset\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(\"gemma1_wiki_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>W</th>\n",
       "      <th>test_prompt</th>\n",
       "      <th>sft_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a879ab05542996e4f30887e</td>\n",
       "      <td>The Oberoi family is part of a hotel company t...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>bridge</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'sent_id': [0, 0], 'title': ['Oberoi family',...</td>\n",
       "      <td>{'sentences': [['The Ritz-Carlton Jakarta is a...</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: Search [Oberoi Group head office location -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a8d7341554299441c6b9fe5</td>\n",
       "      <td>Musician and satirist Allie Goertz wrote a son...</td>\n",
       "      <td>President Richard Nixon</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'sent_id': [0, 1, 2, 0], 'title': ['Allie Goe...</td>\n",
       "      <td>{'sentences': [['Lisa Marie Simpson is a ficti...</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: First, find out [who is Milhouse in The Sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a82171f5542990a1d231f4a</td>\n",
       "      <td>What nationality was James Henry Miller's wife?</td>\n",
       "      <td>American</td>\n",
       "      <td>bridge</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'sent_id': [0, 1, 0], 'title': ['Peggy Seeger...</td>\n",
       "      <td>{'sentences': [['Moloch: or, This Gentile Worl...</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: First, find out [James Henry Miller's wife ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a84dd955542997b5ce3ff79</td>\n",
       "      <td>Cadmium Chloride is slightly soluble in this c...</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>bridge</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'sent_id': [1, 0], 'title': ['Cadmium chlorid...</td>\n",
       "      <td>{'sentences': [['Cadmium chloride is a white c...</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: First, find out [Cadmium Chloride solubilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5adf44985542993a75d2646d</td>\n",
       "      <td>Which genus of moth in the world's seventh-lar...</td>\n",
       "      <td>Crambidae</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'sent_id': [0, 1, 0, 1], 'title': ['Indogramm...</td>\n",
       "      <td>{'sentences': [['India, officially the Republi...</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: First, find out [the seventh largest countr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  5a879ab05542996e4f30887e   \n",
       "1  5a8d7341554299441c6b9fe5   \n",
       "2  5a82171f5542990a1d231f4a   \n",
       "3  5a84dd955542997b5ce3ff79   \n",
       "4  5adf44985542993a75d2646d   \n",
       "\n",
       "                                                   Q                        A  \\\n",
       "0  The Oberoi family is part of a hotel company t...                    Delhi   \n",
       "1  Musician and satirist Allie Goertz wrote a son...  President Richard Nixon   \n",
       "2    What nationality was James Henry Miller's wife?                 American   \n",
       "3  Cadmium Chloride is slightly soluble in this c...                  alcohol   \n",
       "4  Which genus of moth in the world's seventh-lar...                Crambidae   \n",
       "\n",
       "     type   level                                   supporting_facts  \\\n",
       "0  bridge  medium  {'sent_id': [0, 0], 'title': ['Oberoi family',...   \n",
       "1  bridge    hard  {'sent_id': [0, 1, 2, 0], 'title': ['Allie Goe...   \n",
       "2  bridge  medium  {'sent_id': [0, 1, 0], 'title': ['Peggy Seeger...   \n",
       "3  bridge  medium  {'sent_id': [1, 0], 'title': ['Cadmium chlorid...   \n",
       "4  bridge    hard  {'sent_id': [0, 1, 0, 1], 'title': ['Indogramm...   \n",
       "\n",
       "                                                   W  \\\n",
       "0  {'sentences': [['The Ritz-Carlton Jakarta is a...   \n",
       "1  {'sentences': [['Lisa Marie Simpson is a ficti...   \n",
       "2  {'sentences': [['Moloch: or, This Gentile Worl...   \n",
       "3  {'sentences': [['Cadmium chloride is a white c...   \n",
       "4  {'sentences': [['India, officially the Republi...   \n",
       "\n",
       "                                         test_prompt  \\\n",
       "0  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "1  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "2  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "3  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "4  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "\n",
       "                                        sft_response  \n",
       "0  C: Search [Oberoi Group head office location -...  \n",
       "1  C: First, find out [who is Milhouse in The Sim...  \n",
       "2  C: First, find out [James Henry Miller's wife ...  \n",
       "3  C: First, find out [Cadmium Chloride solubilit...  \n",
       "4  C: First, find out [the seventh largest countr...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import wikipedia\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')\n",
    "\n",
    "\n",
    "def wikipedia_seach(query):\n",
    "  language_code = 'en'\n",
    "\n",
    "  number_of_results = 3\n",
    "  headers = {\n",
    "    # 'Authorization': 'Bearer YOUR_ACCESS_TOKEN',\n",
    "    'User-Agent': 'YOUR_APP_NAME (YOUR_EMAIL_OR_CONTACT_PAGE)'\n",
    "  }\n",
    "\n",
    "  base_url = 'https://api.wikimedia.org/core/v1/wikipedia/'\n",
    "  endpoint = '/search/page'\n",
    "  url = base_url + language_code + endpoint\n",
    "\n",
    "  search_query = query\n",
    "  parameters = {'q': search_query, 'limit': number_of_results}\n",
    "  response = requests.get(url, headers=headers, params=parameters)\n",
    "  response = json.loads(response.text)\n",
    "\n",
    "  searched_titles=[]\n",
    "  for page in range(len(response['pages'])):\n",
    "    display_title = response['pages'][page]['title']\n",
    "    searched_titles.append(display_title)\n",
    "    response['pages'][page][\"article_url\"] = 'http://en.wikipedia.org/?curid=' + str(response['pages'][page]['id'])\n",
    "    response['pages'][page]['excerpt'] = BeautifulSoup(response['pages'][page]['excerpt']).get_text()\n",
    "\n",
    "  excerpt_text=search_query+\": \"+\"\\n\".join([page['excerpt'] for page in response['pages']])\n",
    "  if(len(searched_titles)!=0):\n",
    "    #go to page whose title+ excerpt is most similar\n",
    "    # Encode search query\n",
    "    query_embedding = sentence_model.encode(search_query)\n",
    "    page_texts = [page['title'] + \": \" + page['excerpt'] for page in response['pages']]\n",
    "    page_embeddings = sentence_model.encode(page_texts)\n",
    "    # Calculate similarity scores for each page\n",
    "    similarities = cosine_similarity([query_embedding], page_embeddings)[0]\n",
    "\n",
    "    title_score_dict = dict(zip(searched_titles, similarities))\n",
    "\n",
    "    # Get the index of the page with the highest similarity\n",
    "    max_similarity_index = similarities.argmax()\n",
    "\n",
    "    # Output the page id with the highest similarity\n",
    "    max_similarity_page_id = response['pages'][max_similarity_index]['id']\n",
    "\n",
    "    try:\n",
    "      a=wikipedia.page(pageid=max_similarity_page_id)\n",
    "      full_content=a.content\n",
    "      return title_score_dict,excerpt_text,full_content\n",
    "    except:\n",
    "      return {},\"\",\"\"\n",
    "  else:\n",
    "    return {},\"\",\"\"\n",
    "\n",
    "def QA(ques, context):\n",
    "  result = question_answerer(question=ques,context=context)\n",
    "  return result['answer'], result['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from text_to_num import text2num\n",
    "\n",
    "url = \"https://google.serper.dev/search\"\n",
    "\n",
    "def google_search(query):\n",
    "  payload = json.dumps({\n",
    "  \"q\": query\n",
    "})\n",
    "  headers = {\n",
    "  'X-API-KEY': '44218db214e14ddca03d1a19c15af17344e35dcf',\n",
    "  'Content-Type': 'application/json'\n",
    "  }\n",
    "  excerpt_text = \"\"\n",
    "  full_content = \"\"\n",
    "  most_similar_snippets = \"\"\n",
    "  title_score_dict = {}\n",
    "\n",
    "\n",
    "  try:\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    response = json.loads(response.text)\n",
    "    #print(response)\n",
    "    if 'answerBox' in response:\n",
    "      if 'snippetHighlighted' in response['answerBox']:\n",
    "        excerpt_text = response['answerBox']['snippetHighlighted'][0]\n",
    "      elif 'answer' in response['answerBox']:\n",
    "        excerpt_text = response['answerBox']['answer']\n",
    "      else:\n",
    "        excerpt_text = response['answerBox']['snippet']\n",
    "      \n",
    "    else:\n",
    "      #print(\"HERE\")\n",
    "      full_content = [results['title'] + \": \" + results['snippet'] for results in response['organic']]\n",
    "\n",
    "    if full_content:\n",
    "      query_embedding = sentence_model.encode(query)\n",
    "      snippet_embeddings = sentence_model.encode(full_content)\n",
    "      similarities = cosine_similarity([query_embedding], snippet_embeddings)[0]\n",
    "      snippets_greater_than_70 = np.where(similarities > 0.50)[0]\n",
    "      most_similar_snippets = \" \".join([full_content[index] for index in snippets_greater_than_70])\n",
    "\n",
    "    return title_score_dict,excerpt_text,most_similar_snippets\n",
    "  except:\n",
    "    return {},\"\",\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>W</th>\n",
       "      <th>test_prompt</th>\n",
       "      <th>sft_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a879ab05542996e4f30887e</td>\n",
       "      <td>The Oberoi family is part of a hotel company t...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>bridge</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'sent_id': [0, 0], 'title': ['Oberoi family',...</td>\n",
       "      <td>{'sentences': [['The Ritz-Carlton Jakarta is a...</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: Search [Oberoi Group head office location -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a8d7341554299441c6b9fe5</td>\n",
       "      <td>Musician and satirist Allie Goertz wrote a son...</td>\n",
       "      <td>President Richard Nixon</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'sent_id': [0, 1, 2, 0], 'title': ['Allie Goe...</td>\n",
       "      <td>{'sentences': [['Lisa Marie Simpson is a ficti...</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: First, find out [who is Milhouse in The Sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a82171f5542990a1d231f4a</td>\n",
       "      <td>What nationality was James Henry Miller's wife?</td>\n",
       "      <td>American</td>\n",
       "      <td>bridge</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'sent_id': [0, 1, 0], 'title': ['Peggy Seeger...</td>\n",
       "      <td>{'sentences': [['Moloch: or, This Gentile Worl...</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: First, find out [James Henry Miller's wife ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a84dd955542997b5ce3ff79</td>\n",
       "      <td>Cadmium Chloride is slightly soluble in this c...</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>bridge</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'sent_id': [1, 0], 'title': ['Cadmium chlorid...</td>\n",
       "      <td>{'sentences': [['Cadmium chloride is a white c...</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: First, find out [Cadmium Chloride solubilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5adf44985542993a75d2646d</td>\n",
       "      <td>Which genus of moth in the world's seventh-lar...</td>\n",
       "      <td>Crambidae</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'sent_id': [0, 1, 0, 1], 'title': ['Indogramm...</td>\n",
       "      <td>{'sentences': [['India, officially the Republi...</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: First, find out [the seventh largest countr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  5a879ab05542996e4f30887e   \n",
       "1  5a8d7341554299441c6b9fe5   \n",
       "2  5a82171f5542990a1d231f4a   \n",
       "3  5a84dd955542997b5ce3ff79   \n",
       "4  5adf44985542993a75d2646d   \n",
       "\n",
       "                                                   Q                        A  \\\n",
       "0  The Oberoi family is part of a hotel company t...                    Delhi   \n",
       "1  Musician and satirist Allie Goertz wrote a son...  President Richard Nixon   \n",
       "2    What nationality was James Henry Miller's wife?                 American   \n",
       "3  Cadmium Chloride is slightly soluble in this c...                  alcohol   \n",
       "4  Which genus of moth in the world's seventh-lar...                Crambidae   \n",
       "\n",
       "     type   level                                   supporting_facts  \\\n",
       "0  bridge  medium  {'sent_id': [0, 0], 'title': ['Oberoi family',...   \n",
       "1  bridge    hard  {'sent_id': [0, 1, 2, 0], 'title': ['Allie Goe...   \n",
       "2  bridge  medium  {'sent_id': [0, 1, 0], 'title': ['Peggy Seeger...   \n",
       "3  bridge  medium  {'sent_id': [1, 0], 'title': ['Cadmium chlorid...   \n",
       "4  bridge    hard  {'sent_id': [0, 1, 0, 1], 'title': ['Indogramm...   \n",
       "\n",
       "                                                   W  \\\n",
       "0  {'sentences': [['The Ritz-Carlton Jakarta is a...   \n",
       "1  {'sentences': [['Lisa Marie Simpson is a ficti...   \n",
       "2  {'sentences': [['Moloch: or, This Gentile Worl...   \n",
       "3  {'sentences': [['Cadmium chloride is a white c...   \n",
       "4  {'sentences': [['India, officially the Republi...   \n",
       "\n",
       "                                         test_prompt  \\\n",
       "0  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "1  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "2  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "3  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "4  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "\n",
       "                                        sft_response  \n",
       "0  C: Search [Oberoi Group head office location -...  \n",
       "1  C: First, find out [who is Milhouse in The Sim...  \n",
       "2  C: First, find out [James Henry Miller's wife ...  \n",
       "3  C: First, find out [Cadmium Chloride solubilit...  \n",
       "4  C: First, find out [the seventh largest countr...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What nationality was James Henry Miller's wife?\n",
      "C: First, find out [James Henry Miller's wife -Wiki-> y1]. Then determine [y1's nationality -QA(What nationality is y1?)-> y2]. The answer is y2.\n",
      "American\n"
     ]
    }
   ],
   "source": [
    "row=2\n",
    "print(df.iloc[row]['Q'])\n",
    "print(df.iloc[row]['sft_response'])\n",
    "print(df.iloc[row]['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_list_tuple(rep): ## DECISION HERE\n",
    "  if(str(type(rep[0]))!=\"<class 'tuple'>\"): #if wikipedia article comes as in query, return empty string as it is anyways invalid\n",
    "    return \"\"\n",
    "  #for QA result, best score string returned\n",
    "  non_empty_rep = [item for item in rep if item]  # Filter out empty tuples\n",
    "  if non_empty_rep:\n",
    "    rep = max(non_empty_rep, key=lambda x: x[1])[0]  # Get the string with the highest score\n",
    "  else:\n",
    "    rep = \"\"  # If all tuples are empty, return an empty string\n",
    "  return str(rep)\n",
    "\n",
    "def get_variables(text):\n",
    "  matches = re.findall(r'\\[(.*?)\\]', text)\n",
    "  variables={}\n",
    "  wiki_searches=[]\n",
    "  errors=[]\n",
    "  variables['all_eqs']=[]\n",
    "\n",
    "  def replace_variable(match):\n",
    "    #print(variables)\n",
    "    rep = variables.get(match.group(), match.group())\n",
    "    if isinstance(rep, list):\n",
    "        rep=process_list_tuple(rep)\n",
    "    return rep\n",
    "\n",
    "  for instruction in matches:\n",
    "    #print('at ', instruction)\n",
    "    #print(variables)\n",
    "    #---WIKI TOOL---\n",
    "    if(instruction.find(\"-Wiki\")!=-1):\n",
    "      query,ans=instruction.split(\" -Wiki-> \") #for in query variables\n",
    "      in_query_var=re.search(r'y\\d+', query)\n",
    "      if(in_query_var):\n",
    "        query=re.sub(r'y\\d+', replace_variable, query)\n",
    "\n",
    "      title_score_dict,excerpt_text,full_content=google_search(query)\n",
    "      #forcing wiki here\n",
    "      #excerpt_text=''\n",
    "      #full_content=''\n",
    "      if not excerpt_text and not full_content:\n",
    "        print('WIKI SEARCH')\n",
    "        title_score_dict,excerpt_text,full_content=wikipedia_seach(query)#wikipedia search\n",
    "        if title_score_dict: #SAVING IN VARIABLES HERE\n",
    "          #print('HERE updating varibale of wiki answer',ans.strip())\n",
    "          variables[ans.strip()] = [excerpt_text, full_content]#replaces the answer variable with extracted content of wiki\n",
    "          wiki_searches.append(title_score_dict)\n",
    "        else:\n",
    "          errors.append(f\"Error: Wikipedia search unsuccessful for query: '{query}'\")\n",
    "          break\n",
    "      else:\n",
    "        variables[ans.strip()] = [excerpt_text, full_content]#replaces the answer variable with extracted content of google \n",
    "\n",
    "    #---QA TOOL---\n",
    "    elif(instruction.find(\"-QA\")!=-1):\n",
    "      q,a=instruction.split(\"->\")\n",
    "      result = re.search(r'\\((.*?)\\)', q)\n",
    "      if result:\n",
    "          question = result.group(1)\n",
    "      else:\n",
    "          errors.append(\"Error in finding question\")\n",
    "          continue\n",
    "\n",
    "      pre=q.split(\" -QA\")[0]\n",
    "      context_exc=\"\"\n",
    "      full_context=\"\"\n",
    "      if (pre.find(\"+\")!=-1): #if multiple contexts need to be appended\n",
    "\n",
    "        vars=pre.split(\"+\")\n",
    "        for i in vars:\n",
    "          if(i.strip() in variables.keys()):\n",
    "            if((str(type(variables[i.strip()][0]))!=\"<class 'tuple'>\")):\n",
    "              context_exc=variables[i.strip()][0] #if variable came from wiki search, it would be a string else it would be a tuple\n",
    "              full_context=variables[i.strip()][1]\n",
    "            else:\n",
    "              t=process_list_tuple(variables[i.strip()])\n",
    "              #print('-----t',t)\n",
    "              context_exc=t #if variable came from wiki search, it would be a string else it would be a tuple\n",
    "              full_context=t\n",
    "          else:\n",
    "            errors.append(f\"Error: Context variable '{i.strip()}' not found\")\n",
    "            break\n",
    "\n",
    "      else: #single context QA\n",
    "        context_var=pre.strip()\n",
    "        if context_var in variables.keys():\n",
    "          if((str(type(variables[context_var][0]))!=\"<class 'tuple'>\")):\n",
    "            context_exc=variables[context_var][0] #if variable came from wiki search, it would be a string else it would be a tuple\n",
    "            full_context=variables[context_var][1]\n",
    "          else:\n",
    "            t=process_list_tuple(variables[context_var])\n",
    "            context_exc=t #if variable came from wiki search, it would be a string else it would be a tuple\n",
    "            full_context=t\n",
    "        else:\n",
    "          errors.append(f\"Error: Context variable '{context_var}' not found\")\n",
    "          break\n",
    "\n",
    "      #cant send empty context to QA model\n",
    "      if(context_exc!=\"\"):\n",
    "        #print(question,context_exc)\n",
    "        execerpt_run=QA(question, context_exc)\n",
    "        if(execerpt_run[-1]<0.75 and len(full_context)>0):\n",
    "          full_run=QA(question, full_context)\n",
    "        else:\n",
    "          full_run=()\n",
    "      else:\n",
    "        execerpt_run=()\n",
    "        if(len(full_context)>0):\n",
    "          full_run=QA(question, full_context)\n",
    "        else:\n",
    "          full_run=()\n",
    "\n",
    "\n",
    "      #print('Updating variable',a.strip())\n",
    "      variables[a.strip()]=[execerpt_run,full_run]\n",
    "\n",
    "    #----MATH TOOL----\n",
    "    else:\n",
    "      #print('going to math tool')\n",
    "      print('at math',instruction)\n",
    "      variables['all_eqs'].append(instruction)\n",
    "      equation_variables = re.findall(r'y\\d+', instruction)\n",
    "      #print('found varibales',equation_variables)\n",
    "      for var in equation_variables:\n",
    "        if(var in variables.keys()):\n",
    "          #print('on', var)\n",
    "          var_ans=process_list_tuple(variables[var])\n",
    "          #print('before process',variables[var])\n",
    "          #print('on process',var_ans)\n",
    "          numbers = re.findall(r'\\d+(?:\\.\\d+)?', var_ans)#we try searching for numbers\n",
    "          if(len(numbers)>0):\n",
    "            #print('adding equation',var, numbers)\n",
    "            variables['all_eqs'].append(var+\" = \"+str(numbers[0])) #making equation for previously retrieved numerical values ### DECISON HERE\n",
    "            errors.append(f\"WARNING: '{str(numbers)}'numbers in var ans\")\n",
    "          else:\n",
    "            try:\n",
    "              #var_ans=str(text2num(var_ans, \"en\"))\n",
    "              var_ans=str(w2n.word_to_num(var_ans))\n",
    "              numbers = re.findall(r'\\d+(?:\\.\\d+)?', var_ans)#we try searching for numbers\n",
    "              if(len(numbers)>0):\n",
    "                #print('adding equation',var, numbers)\n",
    "                variables['all_eqs'].append(var+\" = \"+str(numbers[0])) #making equation for previously retrieved numerical values ### DECISON HERE\n",
    "                errors.append(f\"WARNING: '{str(numbers)}'numbers in var ans\")\n",
    "            except:\n",
    "              print('var ans is not a numeric',var_ans)\n",
    "              errors.append(f\"Error: '{var_ans}' not numeric\")\n",
    "\n",
    "\n",
    "  return variables,wiki_searches,errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_all(equations):\n",
    "  ans_dict={}\n",
    "  list_eq=[]\n",
    "  for i in equations:\n",
    "    eq=sympify(\"Eq(\" + i.replace(\"=\", \",\") + \")\")\n",
    "    list_eq.append(eq)\n",
    "  #print(list_eq)\n",
    "  result =solve(list_eq)\n",
    "  #print(result)\n",
    "  if(str(type(result))==\"<class 'list'>\"):\n",
    "    result=result[0]\n",
    "  for i in result.keys():\n",
    "      ans_dict[str(i)]=result[i]\n",
    "  return ans_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Oberoi family is part of a hotel company that has a head office in what city?\n",
      "C: Search [Oberoi Group head office city -Wiki-> y1]. The city is [y1 -QA(What is the city of the Oberoi Group head office?)-> y2]. The answer is y2.\n",
      "So, the chain of abstractions for this question would be:\n",
      "Delhi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Oberoi Group head office city -Wiki-> y1',\n",
       " 'y1 -QA(What is the city of the Oberoi Group head office?)-> y2']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row=0\n",
    "print(df.iloc[row]['Q'])\n",
    "print(df.iloc[row]['sft_response'])\n",
    "print(df.iloc[row]['A'])\n",
    "text=df.iloc[row]['sft_response']\n",
    "matches = re.findall(r'\\[(.*?)\\]', text)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "v,w,e=get_variables(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/67 [00:01<01:17,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WIKI SEARCH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 12/67 [00:56<05:10,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at math y1, y2, y3, y4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 28/67 [02:23<02:47,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at math Hate to Feel -Alice in Chains->y1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 37/67 [02:46<00:58,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at math y1\n",
      "at math y2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 43/67 [02:50<00:20,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WIKI SEARCH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 49/67 [02:57<00:19,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at math y2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [03:19<00:00,  2.98s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for row in tqdm(range(33,df.shape[0])):\n",
    "  row_d=df.iloc[row].to_dict()\n",
    "  try:\n",
    "    answer_var=row_d['sft_response'].lower().split(\"answer is\")[-1].replace(\".\",\"\").strip()\n",
    "    variables, wiki_searches, errors = get_variables(row_d['sft_response'])\n",
    "    if(len(variables['all_eqs'])>0):\n",
    "      #solve eqs\n",
    "      try:\n",
    "        variables.update(solve_all(variables['all_eqs']))\n",
    "      except:\n",
    "        errors.append(\"Equaltions not solvable\")\n",
    "    if(answer_var in variables.keys()):\n",
    "      answer=variables[answer_var]\n",
    "    else:\n",
    "      answer=\"not found\"\n",
    "  except:\n",
    "    variables=[]\n",
    "    wiki_searches=[]\n",
    "    errors=['Outer Error Handling']\n",
    "    answer=\"not found\"\n",
    "\n",
    "  row_d['Variables'] = variables\n",
    "  row_d['Searches'] = wiki_searches\n",
    "  row_d['Errors'] = errors\n",
    "  row_d['Generated_answer'] = answer\n",
    "  processed.append(row_d)\n",
    "\n",
    "  # Save to pickle file every 50 rows\n",
    "  if row % 50 == 0 and row != 0:\n",
    "      processed_df = pd.DataFrame(processed)\n",
    "      #processed_df.to_pickle(f'processed_rows_wiki2.pkl')\n",
    "\n",
    "\n",
    "# Save any remaining processed rows to a pickle file\n",
    "if(processed):\n",
    "    processed_df = pd.DataFrame(processed)\n",
    "    #processed_df.to_pickle(f'processed_rows_final_wiki2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>W</th>\n",
       "      <th>test_prompt</th>\n",
       "      <th>sft_response</th>\n",
       "      <th>Variables</th>\n",
       "      <th>Searches</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Generated_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a879ab05542996e4f30887e</td>\n",
       "      <td>The Oberoi family is part of a hotel company t...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>bridge</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'sent_id': [0, 0], 'title': ['Oberoi family',...</td>\n",
       "      <td>{'sentences': [['The Ritz-Carlton Jakarta is a...</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: Search [Oberoi Group head office location -...</td>\n",
       "      <td>{'all_eqs': [], 'y1': ['', 'The Oberoi Group: ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(), (New Delhi, India, 0.8095722794532776)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a8d7341554299441c6b9fe5</td>\n",
       "      <td>Musician and satirist Allie Goertz wrote a son...</td>\n",
       "      <td>President Richard Nixon</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'sent_id': [0, 1, 2, 0], 'title': ['Allie Goe...</td>\n",
       "      <td>{'sentences': [['Lisa Marie Simpson is a ficti...</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: First, find out [who is Milhouse in The Sim...</td>\n",
       "      <td>{'all_eqs': [], 'y1': ['Bart Simpson's best fr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Bart Simpson, 0.9865113496780396), ()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a82171f5542990a1d231f4a</td>\n",
       "      <td>What nationality was James Henry Miller's wife?</td>\n",
       "      <td>American</td>\n",
       "      <td>bridge</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'sent_id': [0, 1, 0], 'title': ['Peggy Seeger...</td>\n",
       "      <td>{'sentences': [['Moloch: or, This Gentile Worl...</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: First, find out [James Henry Miller's wife ...</td>\n",
       "      <td>{'all_eqs': [], 'y1': ['', 'Henry Miller - Wik...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Error: Context variable 'y1's nationality' no...</td>\n",
       "      <td>not found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a84dd955542997b5ce3ff79</td>\n",
       "      <td>Cadmium Chloride is slightly soluble in this c...</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>bridge</td>\n",
       "      <td>medium</td>\n",
       "      <td>{'sent_id': [1, 0], 'title': ['Cadmium chlorid...</td>\n",
       "      <td>{'sentences': [['Cadmium chloride is a white c...</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: First, find out [Cadmium Chloride solubilit...</td>\n",
       "      <td>{'all_eqs': [], 'y1': ['soluble in water (133 ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[, Solubility Rules - Chemistry LibreTexts: Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5adf44985542993a75d2646d</td>\n",
       "      <td>Which genus of moth in the world's seventh-lar...</td>\n",
       "      <td>Crambidae</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'sent_id': [0, 1, 0, 1], 'title': ['Indogramm...</td>\n",
       "      <td>{'sentences': [['India, officially the Republi...</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: First, find out [the seventh largest countr...</td>\n",
       "      <td>{'all_eqs': [], 'y1': ['India', ''], 'y2': ['A...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Aenigmatinea glatzella, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  5a879ab05542996e4f30887e   \n",
       "1  5a8d7341554299441c6b9fe5   \n",
       "2  5a82171f5542990a1d231f4a   \n",
       "3  5a84dd955542997b5ce3ff79   \n",
       "4  5adf44985542993a75d2646d   \n",
       "\n",
       "                                                   Q                        A  \\\n",
       "0  The Oberoi family is part of a hotel company t...                    Delhi   \n",
       "1  Musician and satirist Allie Goertz wrote a son...  President Richard Nixon   \n",
       "2    What nationality was James Henry Miller's wife?                 American   \n",
       "3  Cadmium Chloride is slightly soluble in this c...                  alcohol   \n",
       "4  Which genus of moth in the world's seventh-lar...                Crambidae   \n",
       "\n",
       "     type   level                                   supporting_facts  \\\n",
       "0  bridge  medium  {'sent_id': [0, 0], 'title': ['Oberoi family',...   \n",
       "1  bridge    hard  {'sent_id': [0, 1, 2, 0], 'title': ['Allie Goe...   \n",
       "2  bridge  medium  {'sent_id': [0, 1, 0], 'title': ['Peggy Seeger...   \n",
       "3  bridge  medium  {'sent_id': [1, 0], 'title': ['Cadmium chlorid...   \n",
       "4  bridge    hard  {'sent_id': [0, 1, 0, 1], 'title': ['Indogramm...   \n",
       "\n",
       "                                                   W  \\\n",
       "0  {'sentences': [['The Ritz-Carlton Jakarta is a...   \n",
       "1  {'sentences': [['Lisa Marie Simpson is a ficti...   \n",
       "2  {'sentences': [['Moloch: or, This Gentile Worl...   \n",
       "3  {'sentences': [['Cadmium chloride is a white c...   \n",
       "4  {'sentences': [['India, officially the Republi...   \n",
       "\n",
       "                                         test_prompt  \\\n",
       "0  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "1  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "2  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "3  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "4  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "\n",
       "                                        sft_response  \\\n",
       "0  C: Search [Oberoi Group head office location -...   \n",
       "1  C: First, find out [who is Milhouse in The Sim...   \n",
       "2  C: First, find out [James Henry Miller's wife ...   \n",
       "3  C: First, find out [Cadmium Chloride solubilit...   \n",
       "4  C: First, find out [the seventh largest countr...   \n",
       "\n",
       "                                           Variables Searches  \\\n",
       "0  {'all_eqs': [], 'y1': ['', 'The Oberoi Group: ...       []   \n",
       "1  {'all_eqs': [], 'y1': ['Bart Simpson's best fr...       []   \n",
       "2  {'all_eqs': [], 'y1': ['', 'Henry Miller - Wik...       []   \n",
       "3  {'all_eqs': [], 'y1': ['soluble in water (133 ...       []   \n",
       "4  {'all_eqs': [], 'y1': ['India', ''], 'y2': ['A...       []   \n",
       "\n",
       "                                              Errors  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [Error: Context variable 'y1's nationality' no...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                    Generated_answer  \n",
       "0       [(), (New Delhi, India, 0.8095722794532776)]  \n",
       "1           [(Bart Simpson, 0.9865113496780396), ()]  \n",
       "2                                          not found  \n",
       "3  [, Solubility Rules - Chemistry LibreTexts: Th...  \n",
       "4                         [Aenigmatinea glatzella, ]  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Define the additional functions for similarity checks\n",
    "def exact_match(text1, text2):\n",
    "    return text1 == text2\n",
    "\n",
    "def fuzzy_match(text1, text2):\n",
    "    ratio = fuzz.partial_ratio(text1.lower(), text2.lower())\n",
    "    return ratio\n",
    "\n",
    "def semantic_similarity(text1, text2):\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    embeddings1 = model.encode(text1, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(text2, convert_to_tensor=True)\n",
    "    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    return cosine_scores.item()\n",
    "\n",
    "def semantic_similarity_phrase_bert(text1, text2):\n",
    "    phrase_list = [text1, text2]\n",
    "    model = SentenceTransformer('whaleloops/phrase-bert')\n",
    "    phrase_embs = model.encode(phrase_list)\n",
    "    [p1, p2] = phrase_embs\n",
    "    cos_sim = nn.CosineSimilarity(dim=0)\n",
    "    return cos_sim(torch.tensor(p1), torch.tensor(p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the check_answer function to include new similarity checks\n",
    "def check_answer(row):\n",
    "    gen = row['Generated_answer']\n",
    "    act = row['A']\n",
    "    all_vars = row['Variables']\n",
    "\n",
    "    if exact_match(gen, act):\n",
    "        return True\n",
    "    if str(gen).find(str(act)) != -1:\n",
    "        return True\n",
    "    if str(gen) == str(act):\n",
    "        return True\n",
    "    if fuzzy_match(str(gen), act) > 80:  # You can adjust the threshold for fuzzy matching\n",
    "        return True\n",
    "    if semantic_similarity(str(gen), act) > 0.6:  # Adjust the threshold for semantic similarity\n",
    "        return True\n",
    "    if semantic_similarity_phrase_bert(str(gen), act) > 0.6:  # Adjust the threshold for phrase BERT similarity\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modules.json: 100%|██████████| 349/349 [00:00<00:00, 718kB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 279kB/s]\n",
      "README.md: 100%|██████████| 10.7k/10.7k [00:00<00:00, 4.85MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 91.5kB/s]\n",
      "config.json: 100%|██████████| 612/612 [00:00<00:00, 381kB/s]\n",
      "model.safetensors: 100%|██████████| 90.9M/90.9M [00:01<00:00, 59.2MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 187kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 17.3MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 9.40MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 266kB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 431kB/s]\n",
      "modules.json: 100%|██████████| 229/229 [00:00<00:00, 417kB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 290kB/s]\n",
      "README.md: 100%|██████████| 5.41k/5.41k [00:00<00:00, 2.78MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 52.0/52.0 [00:00<00:00, 101kB/s]\n",
      "config.json: 100%|██████████| 670/670 [00:00<00:00, 1.30MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 438M/438M [00:07<00:00, 55.4MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 632/632 [00:00<00:00, 353kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 10.6MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 12.0MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 64.3kB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 108kB/s]\n",
      "100%|██████████| 200/200 [05:40<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming 'processed_df' is your DataFrame\n",
    "tqdm.pandas()  # Initialize tqdm with pandas\n",
    "\n",
    "# Apply the check_answer function with a progress bar\n",
    "processed_df['is_final_in_solved'] = processed_df.progress_apply(check_answer, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df['is_final_in_solved'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the rows where final_answer is present in solved_answer list\n",
    "count_valid = processed_df[processed_df['is_final_in_solved']].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.to_csv(\"WIKI_GEMMA_result_big_model.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
