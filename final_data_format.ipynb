{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "#from datasets import load_dataset\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_pickle(\"all_data_finals/atFinal-gpt_syn_multitool-1.pkl\")\n",
    "df2=pd.read_pickle(\"all_data_finals/atFinal-maths600.pkl\")\n",
    "df3=pd.read_pickle(\"all_data_finals/atFinal-wikitool.pkl\")\n",
    "df4=pd.read_csv(\"all_data_finals/final_common_sense_gpt_validated.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 9)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=pd.read_csv(\"all_data_finals/common_sense_gemini_validated.csv\")\n",
    "solved_rows_df = df5[df5['is_final_in_solved'] == True]\n",
    "solved_rows_df.shape\n",
    "df4 = pd.concat([df4, solved_rows_df], axis=0)\n",
    "df4.reset_index(drop=True, inplace=True)\n",
    "df4=df4.rename(columns={'question': 'Q', 'answer': 'A'})\n",
    "df4.to_pickle('all_data_finals/common_sense_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 'Q' and 'C' columns from each DataFrame\n",
    "df1_selected = df1[['Q', 'C']]\n",
    "df2_selected = df2[['Q', 'C']]\n",
    "df3_selected = df3[['Q', 'C']]\n",
    "df4_selected = df4[['Q', 'C']]\n",
    "\n",
    "# Concatenate selected columns into a new DataFrame\n",
    "new_df = pd.concat([df1_selected, df2_selected, df3_selected, df4_selected], ignore_index=True)\n",
    "\n",
    "# Shuffle the rows\n",
    "new_df = new_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1543, 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aubrey and Ava are running a km long race. Aub...</td>\n",
       "      <td>First search [number of meters in km -Wiki-&gt; y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The 1950 BRDC International Trophy included wh...</td>\n",
       "      <td>First search [1950 BRDC International Trophy e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anthony spends 6 hours at work, 6 hours on oth...</td>\n",
       "      <td>First search [number of hours in a day -Wiki-&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rick has 130 cards. He decided to only keep 15...</td>\n",
       "      <td>After keeping 15 cards, Rick had [130 - 15 = y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who wrote and directed the film in which Adam ...</td>\n",
       "      <td>First, determine [Adam Beach character in \"Sui...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Q  \\\n",
       "0  Aubrey and Ava are running a km long race. Aub...   \n",
       "1  The 1950 BRDC International Trophy included wh...   \n",
       "2  Anthony spends 6 hours at work, 6 hours on oth...   \n",
       "3  Rick has 130 cards. He decided to only keep 15...   \n",
       "4  Who wrote and directed the film in which Adam ...   \n",
       "\n",
       "                                                   C  \n",
       "0  First search [number of meters in km -Wiki-> y...  \n",
       "1  First search [1950 BRDC International Trophy e...  \n",
       "2  First search [number of hours in a day -Wiki->...  \n",
       "3  After keeping 15 cards, Rick had [130 - 15 = y...  \n",
       "4  First, determine [Adam Beach character in \"Sui...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_pickle(\"all_data_finals/Training_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.read_pickle(\"all_data_finals/Training_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the DataFrame into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(new_df, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and drop the old index column for train_df\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "# Reset index and drop the old index column for valid_df\n",
    "valid_df = valid_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (1311, 2)\n",
      "Validation set shape: (232, 2)\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of the train and validation sets\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Validation set shape:\", valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle(\"all_data_finals/tool_train.pkl\")\n",
    "valid_df.to_pickle(\"all_data_finals/tool_val.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MISTRAL TEMPLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEW DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_pickle(\"all_data_finals/atFinal-gpt_syn_multitool-1.pkl\")\n",
    "df2=pd.read_pickle(\"all_data_finals/atFinal-maths600.pkl\")\n",
    "df3=pd.read_pickle(\"all_data_finals/atFinal-wikitool.pkl\")\n",
    "df4=pd.read_pickle(\"all_data_finals/common_sense_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=\"Math\"\n",
    "t2=\"Wiki and QA\"\n",
    "t3=\"Wiki, QA and Math\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Tools'] =t3\n",
    "df2['Tools'] =t1\n",
    "df3['Tools'] =t2\n",
    "df4['Tools'] =t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 'Q' and 'C' columns from each DataFrame\n",
    "df1_selected = df1[['Q', 'C','Tools']]\n",
    "df2_selected = df2[['Q', 'C','Tools']]\n",
    "df3_selected = df3[['Q', 'C','Tools']]\n",
    "df4_selected = df4[['Q', 'C','Tools']]\n",
    "\n",
    "# Concatenate selected columns into a new DataFrame\n",
    "new_df = pd.concat([df1_selected, df2_selected, df3_selected, df4_selected], ignore_index=True)\n",
    "\n",
    "# Shuffle the rows\n",
    "new_df = new_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1543, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_pickle(\"all_data_finals/tool_training_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (1311, 3)\n",
      "Validation set shape: (232, 3)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the DataFrame into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(new_df, test_size=0.15, random_state=42)\n",
    "# Reset index and drop the old index column for train_df\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "# Reset index and drop the old index column for valid_df\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "# Display the shapes of the train and validation sets\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Validation set shape:\", valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle(\"all_data_finals/tool2_train.pkl\")\n",
    "valid_df.to_pickle(\"all_data_finals/tool2_val.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"### INSTRUCTION\n",
    "Your task is to generate a chain of abstractions (C) for the given question (Q) using the available tools: Wiki, QA, and Mathematical. You can use a single tool or a combination of tools to derive the answer (C). Follow the rules and formats provided for each tool:                               \n",
    "**Tools:** \n",
    "1. **Wiki Tool:** Retrieves relevant articles from Wikipedia. * **Format:** `[search query -Wiki-> search query output]` \n",
    "2. **QA Tool:** Extracts focused answers from Wikipedia articles. * **Format:** `[input context -QA(question)-> output]` \n",
    "3. **Math Tool:** Solves mathematical computations based on information returned from the QA tool. * **Format:** `[polynomial expression]` (e.g., `[y1 + 20 = y2]`)\n",
    "\n",
    "See examples below on how to decide which tools to use and their usage to generate C.\n",
    "### EXAMPLES\n",
    " \n",
    "Example 1 : Only Math tool used                                            \n",
    "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees will the grove workers plant today?\n",
    "Tools: Math\n",
    "C: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been [21 - 15 = y1]. The answer is y1.\n",
    "\n",
    "Example 2 : Wiki tool and QA tool used                                            \n",
    "Q: Fritz von Brodowski was killed during what global war that lasted from 1939 to 1945?\n",
    "Tools: Wiki and QA\n",
    "C: Find the [war in which Fritz von Brodowski was killed -Wiki-> y1]. Fritz von Brodowski was killed in [y1 -QA(Fritz von Brodowski was killed in which war?)-> y2]. The answer is y2.\n",
    "\n",
    "Example 3 : Wiki tool ,QA tool and Math tool used                                           \n",
    "Q: What would be the length of the track where the 2013 Liqui Moly Bathurst 12 Hour was staged, if it would have been 4km longer?\n",
    "Tools: Wiki, QA and Math\n",
    "C: First search for [Mount Panorama Circuit -Wiki-> y1]. Length of circuit is [y1 -QA(what is the length of Mount Panorama Circuit ?)-> y2]. Length after adding 4km will be [4 + y2 = y3]. The answer is y3.\n",
    "\n",
    "Now Generate C for the following Q.  Respond in following format\n",
    "Tool: <Tools that should be used to answer the Q>\n",
    "C: <chain of abstractions for Q>\n",
    "                                  \n",
    "### QUESTION\n",
    "Q: {prompt_q}\n",
    "                                                                                               \n",
    "### RESPONSE\n",
    "Tools: {tools_used}\n",
    "C: {prompt_tool}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GO SEPARATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_pickle(\"all_data_finals/atFinal-gpt_syn_multitool-1.pkl\")\n",
    "df2=pd.read_pickle(\"all_data_finals/atFinal-maths600.pkl\")\n",
    "df3=pd.read_pickle(\"all_data_finals/atFinal-wikitool.pkl\")\n",
    "df4=pd.read_pickle(\"all_data_finals/common_sense_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_selected = df1[['Q', 'C']]\n",
    "df2_selected = df2[['Q', 'C']]\n",
    "df3_selected = df3[['Q', 'C']]\n",
    "df4_selected = df4[['Q', 'C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate selected columns into a new DataFrame\n",
    "new_df = pd.concat([df1_selected, df4_selected], ignore_index=True)\n",
    "# Shuffle the rows\n",
    "new_df = new_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (358, 2)\n",
      "Validation set shape: (64, 2)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the DataFrame into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(new_df, test_size=0.15, random_state=42)\n",
    "# Reset index and drop the old index column for train_df\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "# Reset index and drop the old index column for valid_df\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "# Display the shapes of the train and validation sets\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Validation set shape:\", valid_df.shape)\n",
    "\n",
    "train_df.to_pickle(\"sep_data/multi-tool_train.pkl\")\n",
    "valid_df.to_pickle(\"sep_data/multi-tool_val.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (442, 9)\n",
      "Validation set shape: (79, 9)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the DataFrame into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(df3, test_size=0.15, random_state=42)\n",
    "# Reset index and drop the old index column for train_df\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "# Reset index and drop the old index column for valid_df\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "# Display the shapes of the train and validation sets\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Validation set shape:\", valid_df.shape)\n",
    "\n",
    "train_df.to_pickle(\"sep_data/wiki_train.pkl\")\n",
    "valid_df.to_pickle(\"sep_data/wiki_val.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
