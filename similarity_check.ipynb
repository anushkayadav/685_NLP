{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vVCIgFT4u03p"},"outputs":[],"source":["from fuzzywuzzy import fuzz\n","from sentence_transformers import SentenceTransformer, util\n","import nltk\n","import torch\n","from torch import nn\n","\n","def exact_match(text1, text2):\n","    return text1 == text2\n","\n","def fuzzy_match(text1, text2):\n","    ratio = fuzz.partial_ratio(text1.lower(), text2.lower())\n","    return ratio\n","\n","def semantic_similarity(text1, text2):\n","    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n","    embeddings1 = model.encode(text1, convert_to_tensor=True)\n","    embeddings2 = model.encode(text2, convert_to_tensor=True)\n","    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n","    return cosine_scores.item()\n","\n","def semantic_similarity_phrase_bert(text1, text2):\n","    phrase_list = [text1, text2]\n","    model = SentenceTransformer('whaleloops/phrase-bert')\n","    phrase_embs = model.encode( phrase_list )\n","    [p1, p2] = phrase_embs\n","    cos_sim = nn.CosineSimilarity(dim=0)\n","    return cos_sim(torch.tensor(p1), torch.tensor(p2))"]}]}