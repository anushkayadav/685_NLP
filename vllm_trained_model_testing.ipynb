{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anushkayadav_umass_edu/.conda/envs/llmal/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-18 00:56:53.377556: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-18 00:56:55.649222: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import tqdm as notebook_tqdm\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig,AutoConfig\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import DPOTrainer, SFTTrainer\n",
    "import bitsandbytes as bnb\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "from transformers import TrainerCallback, TrainerState, TrainerControl, Trainer\n",
    "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "#check gpu\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(\"GPU Available\")\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'SAVED_MISTRAL_multitool/sft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-18 00:57:07,481\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-18 00:57:07 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='SAVED_MISTRAL_multitool/sft', tokenizer='SAVED_MISTRAL_multitool/sft', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n",
      "INFO 05-18 00:57:07 selector.py:40] Cannot use FlashAttention backend for Volta and Turing GPUs.\n",
      "INFO 05-18 00:57:07 selector.py:25] Using XFormers backend.\n",
      "INFO 05-18 00:57:38 model_runner.py:104] Loading model weights took 13.4966 GB\n",
      "INFO 05-18 00:57:45 gpu_executor.py:94] # GPU blocks: 12279, # CPU blocks: 2048\n",
      "INFO 05-18 00:57:48 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 05-18 00:57:48 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 05-18 00:58:00 model_runner.py:867] Graph capturing finished in 12 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "llm = LLM(model=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEMMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gsm8k = 'test_data/test_gsm8k100.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset :  Dataset({\n",
      "    features: ['Q', 'answer', 'A', 'test_prompt'],\n",
      "    num_rows: 100\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Define the generate_prompt function\n",
    "def generate_prompt(data_point):\n",
    "    # Generate prompt\n",
    "    instruction = \"Please generate the tool planner answer for the question using tool calls in square brackets\\n\"\n",
    "    prefix_text = 'Generate the Tool Planner Answer for the given question.\\n\\n'\n",
    "    text = f\"\"\"<start_of_turn>user\\n{prefix_text}{instruction}here is the question\\n{data_point[\"Q\"]} <end_of_turn>\\n<start_of_turn>model\\n\"\"\"\n",
    "    return text\n",
    "\n",
    "train=pd.read_pickle(test_gsm8k)\n",
    "train_dataset =  Dataset.from_pandas(train)\n",
    "\n",
    "# Apply the generate_prompt function and add the \"prompt\" column to the dataset\n",
    "text_column = [generate_prompt(data_point) for data_point in train_dataset]\n",
    "train_dataset = train_dataset.add_column(\"test_prompt\", text_column)\n",
    "\n",
    "print(\"Train Dataset : \", train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      "Generate the Tool Planner Answer for the given question.\n",
      "\n",
      "Please generate the tool planner answer for the question using tool calls in square brackets\n",
      "here is the question\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May? <end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset['test_prompt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset['A'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.53s/it]\n"
     ]
    }
   ],
   "source": [
    "#try1\n",
    "sampling_params = SamplingParams(min_tokens=100,max_tokens =1000,top_k=50, top_p=0.95,temperature=0.7,stop=\"<end_of_turn>\", repetition_penalty=1.5)\n",
    "test_instance=train_dataset['test_prompt'][0]#+\"\\n<response>Correct Option\"\n",
    "outputs = llm.generate(test_instance, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In April, Natalie sold 24 clips to her friends. In May, she sold half as many clips as she sold in April, which was 12 clips. So, Natalie sold a total of [24 + 12 = y16 clips]]. answer is y16 . The answer is y16. . . . . . 48+12=y16. answer is y 16. . . 48+24+12=y16. answer is y 36. . . 48+24+12=y16. answer is y 36. The answer is y 36. . . 48+12=y16 answer is y 36. . 48+24+12=y16 answer is y 96. answer is y 96. . 48+24+12=y16 answer is y 96. answer is y 96. .  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96. answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96. answer is y 96.  answer is y 96.  answer is y 96.  answer is y 76. answer is y 96.  answer is y 96.  answer is y 56. answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 096. answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y 96.  answer is y *96*. answer is y -96.  answer is y 96.  answer is y *96*. answer is y *96*. answer is y -96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *96*. answer is y *9\n"
     ]
    }
   ],
   "source": [
    "for output in outputs:\n",
    "    print(output.outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generate_prompt function\n",
    "def generate_prompt(data_point):\n",
    "    # Generate prompt\n",
    "    instruction = \"Please generate the tool planner answer for the question using tool calls in square brackets\\n\"\n",
    "    prefix_text = 'Generate the Tool Planner Answer for the given question.\\n\\n'\n",
    "    text = f\"\"\"<start_of_turn>user\\n{prefix_text}{instruction}here is the question\\n{data_point[\"Q\"]} <end_of_turn>\\n<start_of_turn>model\\n{data_point[\"C\"]} <end_of_turn>\"\"\"\n",
    "    return text\n",
    "\n",
    "train=pd.read_pickle(\"all_data_finals/tool_train.pkl\")\n",
    "eval=pd.read_pickle(\"all_data_finals/tool_val.pkl\")\n",
    "\n",
    "train_dataset =  Dataset.from_pandas(train)\n",
    "eval_dataset = Dataset.from_pandas(eval)\n",
    "\n",
    "# Apply the generate_prompt function and add the \"prompt\" column to the dataset\n",
    "text_column = [generate_prompt(data_point) for data_point in train_dataset]\n",
    "train_dataset = train_dataset.add_column(\"prompt\", text_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      "Generate the Tool Planner Answer for the given question.\n",
      "\n",
      "Please generate the tool planner answer for the question using tool calls in square brackets\n",
      "here is the question\n",
      "What sport did Jack Sock and Raffaella Reggi play? <end_of_turn>\n",
      "<start_of_turn>model\n",
      "First find [Jack Sock -Wiki-> y1]. Then determine [y1 -QA(What sport did Jack Sock play?)-> y2]. Then find [Raffaella Reggi -Wiki-> y3]. Then determine [y3 -QA(What sport did Raffaella Reggi play?)-> y4]. The answer is y2. <end_of_turn>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISTRAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gsm8k = 'test_data/test_commonsense.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 200/200 [00:00<00:00, 6768.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_common = PromptTemplate.from_template(\"\"\"### INSTRUCTION\n",
    "Your task is to generate a chain of abstractions (C) for the given question (Q) using the available tools: Wiki, QA, and Mathematical. You can use a single tool or a combination of tools to derive the answer (C). Follow the rules and formats provided for each tool:                               \n",
    "**Tools:** \n",
    "1. **Wiki Tool:** Retrieves relevant articles from Wikipedia. * **Format:** `[search query -Wiki-> search query output]` \n",
    "2. **QA Tool:** Extracts focused answers from Wikipedia articles. * **Format:** `[input context -QA(question)-> output]` \n",
    "3. **Mathematical Tool:** Solves mathematical computations based on information returned from the QA tool. * **Format:** `[polynomial expression]` (e.g., `[y1 + 20 = y2]`)\n",
    "\n",
    "See examples below on how to decide which tools to use and their usage to generate C.\n",
    "### EXAMPLES\n",
    " \n",
    "Example 1 : Only Math tool used                                            \n",
    "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees will the grove workers plant today?\n",
    "C: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been [21 - 15 = y1]. The answer is y1.\n",
    "\n",
    "Example 2 : Wiki tool and QA tool used                                            \n",
    "Q: Fritz von Brodowski was killed during what global war that lasted from 1939 to 1945?\n",
    "C: Find the [war in which Fritz von Brodowski was killed -Wiki-> y1]. Fritz von Brodowski was killed in [y1 -QA(Fritz von Brodowski was killed in which war?)-> y2]. The answer is y2.\n",
    "\n",
    "Example 3 : Wiki tool ,QA tool and Math tool used                                           \n",
    "Q: What would be the length of the track where the 2013 Liqui Moly Bathurst 12 Hour was staged, if it would have been 4km longer?\n",
    "C: First search for [Mount Panorama Circuit -Wiki-> y1]. Length of circuit is [y1 -QA(what is the length of Mount Panorama Circuit ?)-> y2]. Length after adding 4km will be [4 + y2 = y3]. The answer is y3.\n",
    "\n",
    "Now Generate C for the following Q. Respond in following format\n",
    "C: <chain of abstractions for Q>\n",
    "                                         \n",
    "### QUESTION\n",
    "Q: {prompt_q}\n",
    "                                                                                               \n",
    "### RESPONSE\n",
    "\"\"\")\n",
    "\n",
    "prompt_template_multi = PromptTemplate.from_template(\"\"\"### INSTRUCTION\n",
    "Your task is to generate a chain of abstractions (C) for the given question (Q) using the available tools: Wiki, QA, and Mathematical. You can use a single tool or a combination of tools to derive the answer (C). Follow the rules and formats provided for each tool:                               \n",
    "**Tools:** \n",
    "1. **Wiki Tool:** Retrieves relevant articles from Wikipedia. * **Format:** `[search query -Wiki-> search query output]` \n",
    "2. **QA Tool:** Extracts focused answers from Wikipedia articles. * **Format:** `[input context -QA(question)-> output]` \n",
    "3. **Mathematical Tool:** Solves mathematical computations based on information returned from the QA tool. * **Format:** `[polynomial expression]` (e.g., `[y1 + 20 = y2]`)\n",
    "\n",
    "See examples below on how to decide which tools to use and their usage to generate C.\n",
    "### EXAMPLES\n",
    " \n",
    "Example 1 :                                            \n",
    "Q: An garage has 14 bike wheels. How many bikes he can assemble using 14 wheels?\n",
    "C: First search [number of wheels a bike has -Wiki-> y1].The number of wheels on a single bike are [y1 -QA(How many wheels does a bike have?)-> y2].So, [14/y2 = y3] bikes will be assembled. The answer is y3.\n",
    "\n",
    "Example 2 :                                            \n",
    "Q: Leonardo wants to buy a chocolate.The cost of chocolate is 5 dollars and Leonardo has only 4 dollars in his pocket.He borrowed 59 cents from his friend. How many more cents Leonardo needs now to purchase a chocolate?\n",
    "C: First search [cents in a dollar -Wiki-> y1]. The number of cents in a dollar are[y1 -QA(How many cents in a dollar?)-> y2]. So, choclate costs [5*y2 = y3] cents. He has[4*y2 +59 = y4] cents. Leonardo needs [y3-y4 = y5] cents. The answer is y5.\n",
    "\n",
    "                                               \n",
    "Example 3 :                                      \n",
    "Q: What would be the length of the track where the 2013 Liqui Moly Bathurst 12 Hour was staged, if it would have been 4km longer?\n",
    "C: First search for [Mount Panorama Circuit -Wiki-> y1]. Length of circuit is [y1 -QA(what is the length of Mount Panorama Circuit ?)-> y2]. Length after adding 4km will be [4 + y2 = y3]. The answer is y3.\n",
    "\n",
    "Now Generate C for the following Q. Respond in following format\n",
    "C: <chain of abstractions for Q>\n",
    "                                         \n",
    "### QUESTION\n",
    "Q: {prompt_q}\n",
    "                                                                                               \n",
    "### RESPONSE\n",
    "\"\"\")\n",
    "def create_training_prompt(sample):\n",
    "    prompt_q = sample['Q']\n",
    "    prompt = prompt_template_multi.format(prompt_q=prompt_q)\n",
    "    sample['test_prompt'] = prompt\n",
    "    return sample\n",
    "\n",
    "\n",
    "train=pd.read_pickle(test_gsm8k)\n",
    "train['A'] = train['A'].astype(str)  # Assuming 'A' is the problematic column\n",
    "\n",
    "train_dataset =  Dataset.from_pandas(train).map(create_training_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### INSTRUCTION\n",
      "Your task is to generate a chain of abstractions (C) for the given question (Q) using the available tools: Wiki, QA, and Mathematical. You can use a single tool or a combination of tools to derive the answer (C). Follow the rules and formats provided for each tool:                               \n",
      "**Tools:** \n",
      "1. **Wiki Tool:** Retrieves relevant articles from Wikipedia. * **Format:** `[search query -Wiki-> search query output]` \n",
      "2. **QA Tool:** Extracts focused answers from Wikipedia articles. * **Format:** `[input context -QA(question)-> output]` \n",
      "3. **Mathematical Tool:** Solves mathematical computations based on information returned from the QA tool. * **Format:** `[polynomial expression]` (e.g., `[y1 + 20 = y2]`)\n",
      "\n",
      "See examples below on how to decide which tools to use and their usage to generate C.\n",
      "### EXAMPLES\n",
      " \n",
      "Example 1 :                                            \n",
      "Q: An garage has 14 bike wheels. How many bikes he can assemble using 14 wheels?\n",
      "C: First search [number of wheels a bike has -Wiki-> y1].The number of wheels on a single bike are [y1 -QA(How many wheels does a bike have?)-> y2].So, [14/y2 = y3] bikes will be assembled. The answer is y3.\n",
      "\n",
      "Example 2 :                                            \n",
      "Q: Leonardo wants to buy a chocolate.The cost of chocolate is 5 dollars and Leonardo has only 4 dollars in his pocket.He borrowed 59 cents from his friend. How many more cents Leonardo needs now to purchase a chocolate?\n",
      "C: First search [cents in a dollar -Wiki-> y1]. The number of cents in a dollar are[y1 -QA(How many cents in a dollar?)-> y2]. So, choclate costs [5*y2 = y3] cents. He has[4*y2 +59 = y4] cents. Leonardo needs [y3-y4 = y5] cents. The answer is y5.\n",
      "\n",
      "                                               \n",
      "Example 3 :                                      \n",
      "Q: What would be the length of the track where the 2013 Liqui Moly Bathurst 12 Hour was staged, if it would have been 4km longer?\n",
      "C: First search for [Mount Panorama Circuit -Wiki-> y1]. Length of circuit is [y1 -QA(what is the length of Mount Panorama Circuit ?)-> y2]. Length after adding 4km will be [4 + y2 = y3]. The answer is y3.\n",
      "\n",
      "Now Generate C for the following Q. Respond in following format\n",
      "C: <chain of abstractions for Q>\n",
      "                                         \n",
      "### QUESTION\n",
      "Q: Harper decides to go to a nearby animal farm that has a total of 11 animals. He is standing in a queue near the entry gate, from the gate he could only see legs of the animals in the farm and he counted the total number of legs to be 30. He already knows that there are only ducks and horses in this farm. From this information find the number of ducks\n",
      "                                                                                               \n",
      "### RESPONSE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset['test_prompt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset['A'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.52s/it]\n"
     ]
    }
   ],
   "source": [
    "#try1\n",
    "sampling_params = SamplingParams(min_tokens=50,max_tokens =400,top_k=30, top_p=0.95,temperature=0.3, stop=\"\\n\")\n",
    "test_instance=train_dataset['test_prompt'][0]#+\"\\n<response>Correct Option\"\n",
    "outputs = llm.generate(test_instance, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: First search [total number of legs in a horse -Wiki-> y1]. A horse has [y1 -QA(How many legs does a horse have?) -> y2] legs. A duck has [y3 -Wiki-> y4] legs. The total number of legs in the farm is 30. The number of legs in 11 animals is 11*y2. So, the total number of legs in ducks and horses is 30 = 11*y2 + 11*y4. Solving the equation for y4, y4 = [(30 - 11*y2)/11 -QA-> y5]. The answer is y5.\n"
     ]
    }
   ],
   "source": [
    "for output in outputs:\n",
    "    print(output.outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Q', 'A', 'C', 'test_prompt', 'sft_response'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\n",
      "\n",
      "Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]\n",
      "  0%|          | 1/200 [00:03<12:50,  3.87s/it]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "  1%|          | 2/200 [00:06<09:29,  2.88s/it]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "  2%|▏         | 3/200 [00:07<07:37,  2.32s/it]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "  2%|▏         | 4/200 [00:11<09:27,  2.90s/it]\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "sampling_params = SamplingParams(min_tokens=50,max_tokens =400,top_k=30, top_p=0.95,temperature=0.2, stop=\"\\n\")\n",
    "\n",
    "eval_dataset=train_dataset\n",
    "df=pd.DataFrame(eval_dataset)\n",
    "\n",
    "df['sft_response']='NA'\n",
    "\n",
    "print(df.columns)\n",
    "c=0\n",
    "for i in tqdm(range(len(eval_dataset))):\n",
    "    test_instance=eval_dataset['test_prompt'][i]\n",
    "    outputs = llm.generate(test_instance, sampling_params)\n",
    "    for output in outputs:\n",
    "        generated_text = output.outputs[0].text\n",
    "        df.loc[i,'sft_response']=generated_text\n",
    "    \n",
    "    if(i%20==0):\n",
    "        df.to_pickle('mistral_multi_common_test.pkl')\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "df.to_pickle('mistral_multi_common_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>answer</th>\n",
       "      <th>A</th>\n",
       "      <th>test_prompt</th>\n",
       "      <th>sft_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalia sold clips to 48 of her friends in Apr...</td>\n",
       "      <td>Natalia sold 48/2 = 24 clips in May. Natalia s...</td>\n",
       "      <td>72</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: Natalia sold [48 * 2 = y1] clips in April. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weng earns $12 an hour for babysitting. Yester...</td>\n",
       "      <td>Weng earns 12/60 = $0.2 per minute. Working 50...</td>\n",
       "      <td>10</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: [12 * 50 / 60 = y1]. The answer is y1.\\n \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Betty is saving money for a new wallet which c...</td>\n",
       "      <td>In the beginning, Betty has only 100 / 2 = $50...</td>\n",
       "      <td>5</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: Betty needs [100 - 50 = y1] more money to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Julie is reading a 120-page book. Yesterday, s...</td>\n",
       "      <td>Maila read 12 x 2 = 24 pages today. So she was...</td>\n",
       "      <td>42</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: The answer is [120 - 12 = y1]. She should r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James writes a 3-page letter to 2 different fr...</td>\n",
       "      <td>He writes each friend 3*2=6 pages a week So he...</td>\n",
       "      <td>624</td>\n",
       "      <td>### INSTRUCTION\\nYour task is to generate a ch...</td>\n",
       "      <td>C: First search [number of pages in a week -Wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Q  \\\n",
       "0  Natalia sold clips to 48 of her friends in Apr...   \n",
       "1  Weng earns $12 an hour for babysitting. Yester...   \n",
       "2  Betty is saving money for a new wallet which c...   \n",
       "3  Julie is reading a 120-page book. Yesterday, s...   \n",
       "4  James writes a 3-page letter to 2 different fr...   \n",
       "\n",
       "                                              answer    A  \\\n",
       "0  Natalia sold 48/2 = 24 clips in May. Natalia s...   72   \n",
       "1  Weng earns 12/60 = $0.2 per minute. Working 50...   10   \n",
       "2  In the beginning, Betty has only 100 / 2 = $50...    5   \n",
       "3  Maila read 12 x 2 = 24 pages today. So she was...   42   \n",
       "4  He writes each friend 3*2=6 pages a week So he...  624   \n",
       "\n",
       "                                         test_prompt  \\\n",
       "0  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "1  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "2  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "3  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "4  ### INSTRUCTION\\nYour task is to generate a ch...   \n",
       "\n",
       "                                        sft_response  \n",
       "0  C: Natalia sold [48 * 2 = y1] clips in April. ...  \n",
       "1  C: [12 * 50 / 60 = y1]. The answer is y1.\\n \\n...  \n",
       "2  C: Betty needs [100 - 50 = y1] more money to b...  \n",
       "3  C: The answer is [120 - 12 = y1]. She should r...  \n",
       "4  C: First search [number of pages in a week -Wi...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
