{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxoDyp9PPry6"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install google-generativeai\n",
        "!pip install --upgrade together\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTH6A0bSILGd"
      },
      "outputs": [],
      "source": [
        "!pip install wikipedia\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgaAsbpJIeQh"
      },
      "outputs": [],
      "source": [
        "#!pip install bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epoM6_ZnDlpo",
        "outputId": "8225f605-07a9-4edf-eeb8-7b1b3da3c9c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oXsNR9RTRf-8"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "#from datasets import load_dataset\n",
        "import time\n",
        "import pickle\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGO4LSlhOuUA"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"hotpot_qa\", 'fullwiki')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDJpl-iLPsea"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset['train']\n",
        "train_df = train_dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "RgS-13NaYaux",
        "outputId": "bc3bd794-0470-4b08-b96b-93d3b1def13d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 90447,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90447,\n        \"samples\": [\n          \"5ae5decc5542996de7b71a37\",\n          \"5a8a295a55429930ff3c0cc8\",\n          \"5adc46a055429944faac24b2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90440,\n        \"samples\": [\n          \"Between The Game of Life and Okey, which game has a maximum number of players?\",\n          \"Aksel Sandemose and Erich Maria Remarque, are German?\",\n          \"Is David Allen or Dillian Whyte older?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 53237,\n        \"samples\": [\n          \"Riyadh\",\n          \"Island of the Blue Dolphins\",\n          \"18 November 1984\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"bridge\",\n          \"comparison\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"medium\",\n          \"hard\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"supporting_facts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1bde47e8-3e08-4ead-93de-0147dbecd183\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>type</th>\n",
              "      <th>level</th>\n",
              "      <th>supporting_facts</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5a7a06935542990198eaf050</td>\n",
              "      <td>Which magazine was started first Arthur's Maga...</td>\n",
              "      <td>Arthur's Magazine</td>\n",
              "      <td>comparison</td>\n",
              "      <td>medium</td>\n",
              "      <td>{'title': ['Arthur's Magazine', 'First for Wom...</td>\n",
              "      <td>{'title': ['Radio City (Indian radio station)'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bde47e8-3e08-4ead-93de-0147dbecd183')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1bde47e8-3e08-4ead-93de-0147dbecd183 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1bde47e8-3e08-4ead-93de-0147dbecd183');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                         id  \\\n",
              "0  5a7a06935542990198eaf050   \n",
              "\n",
              "                                            question             answer  \\\n",
              "0  Which magazine was started first Arthur's Maga...  Arthur's Magazine   \n",
              "\n",
              "         type   level                                   supporting_facts  \\\n",
              "0  comparison  medium  {'title': ['Arthur's Magazine', 'First for Wom...   \n",
              "\n",
              "                                             context  \n",
              "0  {'title': ['Radio City (Indian radio station)'...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx85_6W8P5Wg",
        "outputId": "57fd2b85-9821-49c0-a4be-1b777831292b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'title': array([\"Arthur's Magazine\", 'First for Women'], dtype=object),\n",
              " 'sent_id': array([0, 0], dtype=int32)}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.iloc[0]['supporting_facts']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJfEHcN7DgeO",
        "outputId": "6c07b19d-dbe0-447c-cf5c-7e560ca5e5a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/anushka/Downloads'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZcI-bEuQahv"
      },
      "outputs": [],
      "source": [
        "df=pd.read_pickle('/content/drive/MyDrive/NLP project/train_hotpot.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "n_jGyWWRRjHP",
        "outputId": "55964dbd-a155-47c6-beb8-220c056fb4e8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 90447,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90440,\n        \"samples\": [\n          \"Between The Game of Life and Okey, which game has a maximum number of players?\",\n          \"Aksel Sandemose and Erich Maria Remarque, are German?\",\n          \"Is David Allen or Dillian Whyte older?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 53237,\n        \"samples\": [\n          \"Riyadh\",\n          \"Island of the Blue Dolphins\",\n          \"18 November 1984\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"supporting_facts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"W\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 87174,\n        \"samples\": [\n          \"Mesoxantha > Mesoxantha is a genus of nymphalid butterflies. | Mesoxantha >  It is found in Sierra Leone, Guinea, Liberia, Ivory Coast, Ghana, Togo, Nigeria, Cameroon, Gabon, the Republic of the Congo, the Central African Republic, Angola, the Democratic Republic of the Congo, Sudan, Uganda, Tanzania and Mozambique. | Tanzania > Tanzania ( ), officially the United Republic of Tanzania (Swahili: \\\"Jamhuri ya Muungano wa Tanzania\\\" ), is a country in eastern Africa within the African Great Lakes region.\",\n          \"J-14 (magazine) > J-14 is a monthly teenage magazine marketed at preteen and teenage girls around age 11-19. | Awake! > Awake! | Awake! >  is an illustrated religious magazine published every second month by Jehovah's Witnesses via the Watch Tower Bible and Tract Society of Pennsylvania. | Awake! >  It is considered to be a companion magazine of \\\"The Watchtower\\\", and is distributed by Jehovah's Witnesses in their door-to-door ministry.\",\n          \"Johnny &quot;Big Moose&quot; Walker > Johnny \\\"Big Moose\\\" Walker (June 27, 1927 November 27, 1999) was an American Chicago blues and electric blues pianist and organist. | Johnny &quot;Big Moose&quot; Walker >  He worked with many blues musicians, including Ike Turner, Sonny Boy Williamson II, Lowell Fulson, Choker Campbell, Elmore James, Earl Hooker, Muddy Waters, Otis Spann, Sunnyland Slim, Jimmy Dawkins and Son Seals. | Ike Turner > Izear Luster \\\"Ike\\\" Turner, Jr. (November 5, 1931 \\u2013 December 12, 2007) was an American musician, bandleader, songwriter, arranger, talent scout, and record producer.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a693aa4d-3826-40dd-9fb7-5a63bfeb8054\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>supporting_facts</th>\n",
              "      <th>context</th>\n",
              "      <th>W</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Which magazine was started first Arthur's Maga...</td>\n",
              "      <td>Arthur's Magazine</td>\n",
              "      <td>{'title': ['Arthur's Magazine', 'First for Wom...</td>\n",
              "      <td>{'title': ['Radio City (Indian radio station)'...</td>\n",
              "      <td>Arthur's Magazine &gt; Arthur's Magazine (1844–18...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a693aa4d-3826-40dd-9fb7-5a63bfeb8054')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a693aa4d-3826-40dd-9fb7-5a63bfeb8054 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a693aa4d-3826-40dd-9fb7-5a63bfeb8054');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            question             answer  \\\n",
              "0  Which magazine was started first Arthur's Maga...  Arthur's Magazine   \n",
              "\n",
              "                                    supporting_facts  \\\n",
              "0  {'title': ['Arthur's Magazine', 'First for Wom...   \n",
              "\n",
              "                                             context  \\\n",
              "0  {'title': ['Radio City (Indian radio station)'...   \n",
              "\n",
              "                                                   W  \n",
              "0  Arthur's Magazine > Arthur's Magazine (1844–18...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYDCOfiqSH9y"
      },
      "outputs": [],
      "source": [
        "prompt_examples=\"\"\"Example 1\n",
        "Q: Fritz von Brodowski was killed during what global war that lasted from 1939 to 1945?\n",
        "A: The answer is World War II.\n",
        "W: Fritz von Brodowski > Friedrich Wilhelm Konrad von Brodowski was controversially killed while in French custody during World War II.\n",
        "C: Find the [war in which Fritz von Brodowski was killed -Wiki-> y1]. Fritz von Brodowski was killed in [y1 -QA(Fritz von Brodowski was killed in which war?)-> y2]. The answer is y2.\n",
        "\n",
        "Example 2\n",
        "Q: Which tennis player won more Grand Slam titles, Henri Leconte or Jonathan Stark?\n",
        "A: The answer is Jonathan Stark.\n",
        "W: Henri Leconte > He won the French Open men’s doubles title in 1984. | Jonathan Stark (tennis) > During his career he won two Grand Slam doubles titles.\n",
        "C: First Search [Henri Leconte Grand Slam titles  -Wiki-> y1]. Then Search [Jonathan Stark Grand Slam titles  -Wiki-> y2]. [y1+y2 -QA(Which tennis player won more Grand Slam titles, Henri Leconte or Jonathan Stark?)-> y3]. The answer is y3.\n",
        "\n",
        "Example 3\n",
        "Q: The director of the romantic comedy “Big Stone Gap” is based out of which part of New York city?\n",
        "A: The answer is Greenwich Village.\n",
        "W: Big Stone Gap (film) > Big Stone Gap is a 2014 American romantic comedy film directed by Adriana Trigiani. | Adriana Trigiani > Adriana Trigiani is an Italian American film director based in Greenwich Village.\n",
        "C: First search the [Big Stone Gap director -Wiki-> y1]. The name of this film’s director is [y1 -QA(Who is the director of Big Stone Gap?)-> y2]. Then determine [y2 is based out of which city -Wiki-> y3]. The city is [y3 -QA(Where is y2 based out of?)-> y4]. Answer is y4.\n",
        "\n",
        "Example 4\n",
        "Q: Are Randal Kleiser and Kyle Schickner of the same nationality?\n",
        "A: The answer is yes.\n",
        "W: Randal Kleiser > John Randal Kleiser (born July 20, 1946) is an American film director and producer. | Kyle Schickner > Kyle Schickner is an American film producer, writer, director, actor.\n",
        "C: First find out the [Randal Kleiser nationality -Wiki-> y1]. Then figure out the [Kyle Schickner nationality -Wiki-> y2]. Then check [y1+y2 -QA(Are Randal Kleiser and Kyle Schickner of the same nationality?)-> y3]. the answer is y3.\n",
        "\n",
        "Example 5\n",
        "Q: Extras was created, written, and directed by Ricky Dene Gervais, an English comedian, actor, writer, producer, director, singer, and musician, born on which date?\n",
        "A: The answer is 25 June 1961.\n",
        "W: Ricky Gervais > Ricky Dene Gervais (born 25 June 1961) is an English comedian, actor, writer, producer, director, singer, and musician.\n",
        "C: Search [when Ricky Dene Gervais was born -Wiki-> y1].  Then determine [y1 -QA(When Ricky Dene Gervais was born?)-> y2]. The answer is y2.\n",
        "\n",
        "Example 6\n",
        "Q: Sameera Perera is a cricketer from what island country located southeast of the Republic of India and northeast of the Maldives?\n",
        "A: The answer is Sri Lanka.\n",
        "W: Sameera Perera > Sameera Perera (born 20 August 1988) is a Sri Lankan cricketer.\n",
        "C: Search [Sameera Perera -Wiki-> y1]. Then find [y1 -QA(Where is Sameera Perera from?)-> y2]. The answer is y2.\n",
        "\n",
        "Example 7\n",
        "Q: What screenwriter with credits for “Evolution” co-wrote a film starring Nicolas Cage and Téa Leoni?\n",
        "A: The answer is David Weissman.\n",
        "W: The Family Man > The Family Man is a 2000 American romantic comedy-drama film starring Nicolas Cage and Téa Leoni. | David Weissman > His film credits include “The Family Man” (2000), “Evolution” (2001), and “When in Rome” (2010).\n",
        "C: First figure out the [film of Nicolas Cage and Téa Leoni -Wiki-> y1]. The name of this film is [y1 -QA(In which film did Nicolas Cage and Téa Leoni star together?)-> y2]. Then find out [who wrote y2 with credits for “Evolution” -Wiki-> y3]. The name is screenwriter is [y3 -QA(Who wrote y2 with credits for Evolution?)-> y4]. The answer is y4.\n",
        "\n",
        "Example 8\n",
        "Q: Ralph Hefferline was a psychology professor at a university that is located in what city?\n",
        "A: The answer is New York City.\n",
        "W: Ralph Hefferline > Ralph Franklin Hefferline was a psychology professor at Columbia University. | Columbia University > Columbia University is a private Ivy League research university in Upper Manhattan, New York City.\n",
        "C: First identify the [university of psychology professor Ralph Hefferline -Wiki-> y1]. The university of this professor is [y1 -QA(Ralph Hefferlin was a psychology professor at which university?)-> y2]. Then figure out [y2 in which city -Wiki-> y3]. The name is city is [y3 -QA(y2 is in which city?)-> y4]. The answer is y4.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqaNleLcSitR"
      },
      "outputs": [],
      "source": [
        "prompt_rows = df[['question', 'answer','W']].rename(columns={'question': 'Q', 'answer': 'A'}).to_dict('records')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-Gy0GP9kJHi"
      },
      "source": [
        "### TOGETHER AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yNL-GXkUEWw"
      },
      "outputs": [],
      "source": [
        "llama_prompt=f\"\"\"Examples to generate Chain of Abstraction( C)  given Q, A and W are:\n",
        "\n",
        "{prompt_examples}\n",
        "\n",
        "\n",
        "Now  generate C for the test examples below. Please Write \"###DONE\" when you have completed generating C for all of the examples below.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def generate_continuation_llama(prompt_rows):\n",
        "    prompt = llama_prompt\n",
        "\n",
        "    for idx, row in enumerate(prompt_rows):\n",
        "        prompt += f\"Test Example {idx + 1}\\n\"\n",
        "        prompt += f\"Q: {row['Q']}\\n\"\n",
        "        prompt += f\"A: {row['A']}\\n\"\n",
        "        prompt += f\"W: {row['W']}\\n\"\n",
        "        prompt += \"C:\\n\\n\"\n",
        "    return prompt + \"Respond only with C for the test examples. Use this format >> Test Example <number> C : <generated C>\\nChain of Abstractions C for the above test examples are:\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6SVoV1rkYkU"
      },
      "outputs": [],
      "source": [
        "input_prompt=generate_continuation_llama(prompt_rows[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmCZeaZYkbN3"
      },
      "outputs": [],
      "source": [
        "print(input_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArzIgEbMkc9E",
        "outputId": "502cba08-22e9-4022-8c83-73029a53b0cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### DONE\n",
            "\n",
            "Test Example 1\n",
            "Q: Which tennis player won more Grand Slam titles, Henri Leconte or Jonathan Stark?\n",
            "A: Jonathan Stark\n",
            "W: Jonathan Stark (tennis) > Jonathan Stark (born April 3, 1971) is a former professional tennis player from the United States. | Jonathan Stark (tennis) >  During his career he won two Grand Slam doubles titles (the 1994 French Open Men's Doubles and the 1995 Wimbledon Championships Mixed Doubles). | Henri Leconte >  He reached the men's singles final at the French Open in 1988, won the French Open men's doubles title in 1984, and helped France win the Davis Cup in 1991.\n",
            "C: First search [Henri Leconte Grand Slam titles -Wiki-> y1]. Then Search [Jonathan Stark Grand Slam titles  -Wiki-> y2]. [y1+y2 -QA(Which tennis player won more Grand Slam titles, Henri Leconte or Jonathan Stark?)-> y3]. The answer is y3.\n",
            "\n",
            "Test Example 2\n",
            "Q: Which genus of moth in the world's seventh-largest country contains only one species?\n",
            "A: Crambidae\n",
            "W: Indogrammodes > Indogrammodes is a genus of moths of the Crambidae family. | Indogrammodes >  It contains only one species, Indogrammodes pectinicornalis, which is found in India. | India > India, officially the Republic of India (\"Bhārat Gaṇarājya\"), is a country in South Asia. | India >  It is the seventh-largest country by area, the second-most populous country (with over 1.2 billion people), and the most populous democracy in the world.\n",
            "C: Find the [world's seventh-largest country -Wiki-> y1]. Identify the [genus of moth found in y1 -Wiki-> y2]. The genus is [y2 -QA(What genus of moth is found in y1?)-> y3]. The answer is y3.\n",
            "\n",
            "Test Example 3\n",
            "Q: Who was once considered the best kick boxer in the world, however he has been involved in a number of controversies relating to his \"unsportsmanlike conducts\" in the sport and crimes of violence outside of the ring.\n",
            "A: Badr Hari\n",
            "W: Global Fighting Championship >  Fighters from around world on the roster include Badr Hari, Peter Aerts, Peter Graham, Dewey Cooper, Zabit Samedov. | Global Fighting Championship >  It was considered as one of the biggest kickboxing and MMA promotion in Middle East. | Badr Hari > Badr Hari (Arabic: بدر هاري‎ ‎ ; born 8 December 1984) is a Moroccan-Dutch super heavyweight kickboxer from Amsterdam, fighting out of Mike's Gym in Oostzaan. | Badr Hari >  Hari has been a prominent figure in the world of kickboxing and was once considered the best kickboxer in the world, however he has been involved in a number of controversies relating to his \"unsportsmanlike conducts\" in the sport and crimes of violence outside of the ring.\n",
            "C: Identify the [kickboxer who had controversy -Wiki-> y1]. The name of this kickboxer is [y1 -QA(Who was once considered the best kick boxer in the world?)-> y2]. The answer is y2.\n",
            "\n",
            "Test Example 4\n",
            "Q: The Dutch-Belgian television series that \"House of Anubis\" was based on first aired in what year?\n",
            "A: 2006\n",
            "W: House of Anubis > House of Anubis is a mystery television series developed for Nickelodeon based on the Dutch-Belgian television series \"Het Huis Anubis\". | Het Huis Anubis >  It first aired in September 2006 and the last episode was broadcast on December 4, 2009.\n",
            "C: Identify the [television series that \"House of Anubis\" was based on -Wiki-> y1]. The year it first aired is [y1 -QA(When did the Dutch-Belgian television series that \"House of Anubis\" was based on first air?)-> y2]. The answer is y2.\n",
            "\n",
            "Test Example 5\n",
            "Q: What is the length of the track where the 2013 Liqui Moly Bathurst 12 Hour was staged?\n",
            "A: 6.213 km long\n",
            "W: 2013 Liqui Moly Bathurst 12 Hour > The 2013 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars, Group 3E Series Production Cars and Dubai 24 Hour cars. | 2013 Liqui Moly Bathurst 12 Hour >  The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 10 February 2013, was the eleventh running of the Bathurst 12 Hour. | Mount Panorama Circuit > Mount Panorama Circuit is a motor racing track located in Bathurst, New South Wales, Australia. | Mount Panorama Circuit >  The 6.213 km long track is technically a street circuit, and is a public road, with normal speed restrictions, when no racing events are being run, and there are many residences which can only be accessed from the circuit.\n",
            "C: First search [Mount Panorama Circuit track length -Wiki-> y1]. The length is [y1 -QA(What is the length of the track where the 2013 Liqui Moly Bathurst 12 Hour was staged?)-> y2]. The answer is y2.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from together import Together\n",
        "\n",
        "client = Together(api_key=\"<API KEY>\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"meta-llama/Llama-3-8b-chat-hf\",\n",
        "    top_k= 30,\n",
        "    max_tokens=2000,\n",
        "    messages=[{\n",
        "            \"content\": \"You are an agent that converts Questions, Answers and corresponding Wikipedia Knowledge to a Chain of Abstractions. The intuition is to get to the Answer using the facts given in the Wikipedia knowledge Your task to generate Abstractions(C) given Question (Q),Answer (A) and Wikipedia Knowledge (W).\",\"role\": \"system\"},\n",
        "             {\"role\": \"user\", \"content\": input_prompt}],\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utVCim1vmYDU"
      },
      "source": [
        "### GEMINI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJlWratCmXz-"
      },
      "outputs": [],
      "source": [
        "gemini_prompt_old=f\"\"\"You are an agent that converts Questions, Answers and corresponding Wikipedia Knowledge to a Chain of Abstractions. The intuition is to get to the Answer using the facts given in the Wikipedia knowledge Your task to generate Abstractions(C) given Question (Q),Answer (A) and Wikipedia Knowledge (W).\n",
        "Examples to generate Chain of Abstraction( C)  given Q, A and W are:\n",
        "\n",
        "### EXAMPLES\n",
        "{prompt_examples}\n",
        "\n",
        "### TASK\n",
        "Now  generate C for the test examples below. Please Write \"###DONE\" when you have completed generating C for all of the examples below.\n",
        "Respond in this format only:\n",
        "Test Example <example number> C:\n",
        "\n",
        "\"\"\"\n",
        "#PROBLEMS EXIST in above like cheat wiki searches, wrong chains, No QA after WIKI\n",
        "\n",
        "gemini_prompt=f\"\"\"You are an agent that converts Questions, Answers, and corresponding Wikipedia Knowledge to a Chain of Abstractions. The intuition is to get to the Answer using the titles searched in the  Wikipedia knowledge.\n",
        "\n",
        "Rules to generate C:\n",
        "1.  You have 2 tools, Wiki and QA. Use **BOTH tools** to derive C. Tool Explanations are:\n",
        "\tWiki Tool to get relevant articles from Wikipedia. Format: [search query -Wiki-> search query output]\n",
        "\tQA tool to get the focused answer from the Wikipedia articles. Format:  [input context -QA(question)-> output]\n",
        "2. W is formatted to put the title before '>' and content after '>' and separate articles using '|'.\n",
        "3. Use the outputs from Wiki tool as input context for QA tool. The final answer is always output of QA tool. **This is crucial**\n",
        "4. You can use page titles but cannot use page content information given in W to form Wiki search Queries.\n",
        "5. You cannot use answer (A) in the tool queries directly.\n",
        "6. Utilize the Chain of Thought process from the Wikipedia Knowledge given. Learn what titles need to be searched in the Wiki tool and asked in the QA tool to get to the final answer.\n",
        "\n",
        "Your task to generate Abstractions(C)  for the given Question (Q) using both the Wiki tool and the QA tool using the rules.\n",
        "\n",
        "Examples to generate Chain of Abstraction( C)  given Q, A and W are:\n",
        "### EXAMPLES\n",
        "{prompt_examples}\n",
        "\n",
        "### TASK\n",
        "Now  generate C for the test examples below. Please Write '###DONE' when you have completed generating C for all of the examples below.\n",
        "Respond in this format only:\n",
        "Test Example <example number> C:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def generate_continuation_gemini(prompt_rows):\n",
        "    prompt = gemini_prompt\n",
        "\n",
        "    for idx, row in enumerate(prompt_rows):\n",
        "        prompt += f\"Test Example {idx + 1}\\n\"\n",
        "        prompt += f\"Q: {row['Q']}\\n\"\n",
        "        prompt += f\"A: {row['A']}\\n\"\n",
        "        prompt += f\"W: {row['W']}\\n\"\n",
        "        prompt += \"\\n\"\n",
        "    return prompt + \"### RESPONSE\\n\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3lbh878TmngA"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=\"<API KEY>\")\n",
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.9,\n",
        "  \"top_p\": 1,\n",
        "  \"top_k\": 0,\n",
        "  \"max_output_tokens\": 3000,\n",
        "}\n",
        "\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro-latest\",#\"gemini-1.5-pro-latest\",\n",
        "                              generation_config=generation_config)\n",
        "\n",
        "def get_muti_c(rows):\n",
        "  input_prompt=generate_continuation_gemini(rows)\n",
        "  prompt_parts = [input_prompt]\n",
        "  response = model.generate_content(prompt_parts)\n",
        "  contents = re.findall(r'C:(.*)', response.text)\n",
        "\n",
        "  if len(contents)==5:\n",
        "    # Add each element of content to the corresponding row\n",
        "    for i, row in enumerate(rows):\n",
        "        row['C'] = contents[i].strip()\n",
        "    return 'success',rows\n",
        "  else:\n",
        "    rows.append({\"content\":contents})\n",
        "    print(\"FAIL\")\n",
        "    return 'fail',rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "4-iuccGcIzr7",
        "outputId": "134b70c6-6457-4a73-b42b-dd5924081140"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'prompt_rows' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c42babcbaef2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_muti_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_rows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'prompt_rows' is not defined"
          ]
        }
      ],
      "source": [
        "get_muti_c(prompt_rows[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3N2WQXR3x_d"
      },
      "outputs": [],
      "source": [
        "input_prompt=generate_continuation_gemini(prompt_rows[5:10])\n",
        "print(input_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-N7K_gT3XI8"
      },
      "outputs": [],
      "source": [
        "len(prompt_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuZovWiTnKBX"
      },
      "outputs": [],
      "source": [
        "prompt_rows=prompt_rows[:5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIUoiYhK3ZPG"
      },
      "outputs": [],
      "source": [
        "generated_dataset = []\n",
        "failed = []\n",
        "\n",
        "for i in tqdm(range(0, len(prompt_rows), 5)):\n",
        "    batch = prompt_rows[i:i+5]\n",
        "\n",
        "    time.sleep(4)\n",
        "    try:\n",
        "\n",
        "      status, gen_batch = get_muti_c(batch)\n",
        "      if status == 'success':\n",
        "          generated_dataset.extend(gen_batch)\n",
        "      else:\n",
        "          failed.append(gen_batch)\n",
        "\n",
        "      # Save generated_dataset to DataFrame pickle file after every5 iterations\n",
        "      if (i + 1) % 10 == 0:\n",
        "          df = pd.DataFrame(generated_dataset)\n",
        "          df.to_pickle(f'\"/content/drive/MyDrive/NLP project/Wiki_tool/wiki_generated_dataset_2.pkl')\n",
        "          print(f'Saved generated_dataset_{i+1}.pkl')\n",
        "\n",
        "          if len(failed) > 0:\n",
        "            with open('/content/drive/MyDrive/NLP project/Wiki_tool/wiki_failed_data.pkl', 'wb') as file:\n",
        "              pickle.dump(failed, file)\n",
        "            print('Saved failed_data.pkl')\n",
        "    except:\n",
        "      print('REQUEST FAIL')\n",
        "      pass\n",
        "\n",
        "\n",
        "# Save any remaining data\n",
        "if len(generated_dataset) > 0:\n",
        "    df = pd.DataFrame(generated_dataset)\n",
        "    df.to_pickle('/content/drive/MyDrive/NLP project/Wiki_tool/wiki_generated_dataset_2.pkl')\n",
        "    print('Saved generated_dataset_2.pkl')\n",
        "\n",
        "if len(failed) > 0:\n",
        "    with open('/content/drive/MyDrive/NLP project/Wiki_tool/wiki_failed_data.pkl', 'wb') as file:\n",
        "      pickle.dump(failed, file)\n",
        "    print('Saved failed_data.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEj7DLZj5Zxh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6eOyK5cD4AH"
      },
      "source": [
        "### CHECK GENERATED DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D1JvdxCmD6eU"
      },
      "outputs": [],
      "source": [
        "#df=pd.read_pickle(\"/content/drive/MyDrive/NLP project/Wiki_tool/wiki_generated_dataset_2.pkl\")\n",
        "df=pd.read_pickle(\"wiki_generated_dataset_2.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dKlH3jMoD9ac",
        "outputId": "36489504-406c-450c-df49-7d3742689a4f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>W</th>\n",
              "      <th>C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Which magazine was started first Arthur's Maga...</td>\n",
              "      <td>Arthur's Magazine</td>\n",
              "      <td>Arthur's Magazine &gt; Arthur's Magazine (1844–18...</td>\n",
              "      <td>Find out [Arthur's Magazine or First for Women...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Oberoi family is part of a hotel company t...</td>\n",
              "      <td>Delhi</td>\n",
              "      <td>Oberoi family &gt; The Oberoi family is an Indian...</td>\n",
              "      <td>Find out [The Oberoi Group head office city -W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Musician and satirist Allie Goertz wrote a son...</td>\n",
              "      <td>President Richard Nixon</td>\n",
              "      <td>Allie Goertz &gt; Allison Beth \"Allie\" Goertz (bo...</td>\n",
              "      <td>First search [who does the character Milhouse ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What nationality was James Henry Miller's wife?</td>\n",
              "      <td>American</td>\n",
              "      <td>Peggy Seeger &gt; Margaret \"Peggy\" Seeger (born J...</td>\n",
              "      <td>First find out [wife of James Henry Miller -Wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cadmium Chloride is slightly soluble in this c...</td>\n",
              "      <td>alcohol</td>\n",
              "      <td>Cadmium chloride &gt;  It is a hygroscopic solid ...</td>\n",
              "      <td>First find out [Cadmium Chloride is soluble in...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Q                        A  \\\n",
              "0  Which magazine was started first Arthur's Maga...        Arthur's Magazine   \n",
              "1  The Oberoi family is part of a hotel company t...                    Delhi   \n",
              "2  Musician and satirist Allie Goertz wrote a son...  President Richard Nixon   \n",
              "3    What nationality was James Henry Miller's wife?                 American   \n",
              "4  Cadmium Chloride is slightly soluble in this c...                  alcohol   \n",
              "\n",
              "                                                   W  \\\n",
              "0  Arthur's Magazine > Arthur's Magazine (1844–18...   \n",
              "1  Oberoi family > The Oberoi family is an Indian...   \n",
              "2  Allie Goertz > Allison Beth \"Allie\" Goertz (bo...   \n",
              "3  Peggy Seeger > Margaret \"Peggy\" Seeger (born J...   \n",
              "4  Cadmium chloride >  It is a hygroscopic solid ...   \n",
              "\n",
              "                                                   C  \n",
              "0  Find out [Arthur's Magazine or First for Women...  \n",
              "1  Find out [The Oberoi Group head office city -W...  \n",
              "2  First search [who does the character Milhouse ...  \n",
              "3  First find out [wife of James Henry Miller -Wi...  \n",
              "4  First find out [Cadmium Chloride is soluble in...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9IY8dzUEAXh",
        "outputId": "642cb736-8a34-4df7-faf0-0b8a9ada6a2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4880, 4)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "-iwB9yBKkZmH"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "from pprint import pprint\n",
        "import wikipedia\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "from transformers import pipeline\n",
        "question_answerer = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')\n",
        "\n",
        "\n",
        "def wikipedia_seach(query):\n",
        "  language_code = 'en'\n",
        "\n",
        "  number_of_results = 3\n",
        "  headers = {\n",
        "    # 'Authorization': 'Bearer YOUR_ACCESS_TOKEN',\n",
        "    'User-Agent': 'YOUR_APP_NAME (YOUR_EMAIL_OR_CONTACT_PAGE)'\n",
        "  }\n",
        "\n",
        "  base_url = 'https://api.wikimedia.org/core/v1/wikipedia/'\n",
        "  endpoint = '/search/page'\n",
        "  url = base_url + language_code + endpoint\n",
        "\n",
        "  search_query = query\n",
        "  parameters = {'q': search_query, 'limit': number_of_results}\n",
        "  response = requests.get(url, headers=headers, params=parameters)\n",
        "  response = json.loads(response.text)\n",
        "  print(response)\n",
        "  searched_titles=[]\n",
        "  for page in range(len(response['pages'])):\n",
        "    display_title = response['pages'][page]['title']\n",
        "    searched_titles.append(display_title)\n",
        "    response['pages'][page][\"article_url\"] = 'http://en.wikipedia.org/?curid=' + str(response['pages'][page]['id'])\n",
        "    response['pages'][page]['excerpt'] = BeautifulSoup(response['pages'][page]['excerpt']).get_text()\n",
        "\n",
        "  excerpt_text=search_query+\": \"+\"\\n\".join([page['excerpt'] for page in response['pages']])\n",
        "  if(len(searched_titles)!=0):\n",
        "    #go to page whose title+ excerpt is most similar\n",
        "    # Encode search query\n",
        "    query_embedding = sentence_model.encode(search_query)\n",
        "    page_texts = [page['title'] + \": \" + page['excerpt'] for page in response['pages']]\n",
        "    page_embeddings = sentence_model.encode(page_texts)\n",
        "    # Calculate similarity scores for each page\n",
        "    similarities = cosine_similarity([query_embedding], page_embeddings)[0]\n",
        "\n",
        "    title_score_dict = dict(zip(searched_titles, similarities))\n",
        "\n",
        "    # Get the index of the page with the highest similarity\n",
        "    max_similarity_index = similarities.argmax()\n",
        "\n",
        "    # Output the page id with the highest similarity\n",
        "    max_similarity_page_id = response['pages'][max_similarity_index]['id']\n",
        "\n",
        "    try:\n",
        "      a=wikipedia.page(pageid=max_similarity_page_id)\n",
        "      full_content=a.content\n",
        "      return title_score_dict,excerpt_text,full_content\n",
        "    except:\n",
        "      return {},\"\",\"\"\n",
        "  else:\n",
        "    return {},\"\",\"\"\n",
        "\n",
        "def QA(ques, context):\n",
        "  result = question_answerer(question=ques,context=context)\n",
        "  return result['answer'], result['score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5tyaqVXrEB5Z"
      },
      "outputs": [],
      "source": [
        "## CHECKING STEP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jrNL5HjLEEi4"
      },
      "outputs": [],
      "source": [
        "# first level scoring on wikipedia search\n",
        "#is wikipedia top3 matching the titles in W\n",
        "#if answer not found in excerpts , go to main wikipedia page contet whose title/excerpt matches highest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A47emrf4bssU",
        "outputId": "1227d5fb-3ca6-4fb6-f9fc-91fc32e925de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What was the franchise, in which Anton Šťastný played 9 seasons, renamed after moving in 1995?\n",
            "Anton Šťastný > Anton Šťastný (born August 5, 1959) is a former Slovak professional ice hockey left winger who played nine seasons with the Quebec Nordiques of the National Hockey League from 1980 until 1989. | Quebec Nordiques >  The franchise was relocated to Denver, Colorado in May 1995 and renamed the Colorado Avalanche.\n",
            "First find out the [team Anton Šťastný played for for 9 seasons -Wiki-> y1]. Then Find [the renamed franchise after y1 moved in 1995 -Wiki-> y2]. The answer is y2.\n",
            "Colorado Avalanche\n"
          ]
        }
      ],
      "source": [
        "row=678\n",
        "print(df.iloc[row]['Q'])\n",
        "print(df.iloc[row]['W'])\n",
        "print(df.iloc[row]['C'])\n",
        "print(df.iloc[row]['A'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "bxrvWvH7Sa31"
      },
      "outputs": [],
      "source": [
        "def process_list_tuple(rep):\n",
        "  if(str(type(rep[0]))!=\"<class 'tuple'>\"): #if wikipedia article comes as in query, return empty string as it is anyways invalid\n",
        "    return \"\"\n",
        "  #for QA result, best score string returned\n",
        "  non_empty_rep = [item for item in rep if item]  # Filter out empty tuples\n",
        "  if non_empty_rep:\n",
        "    rep = max(non_empty_rep, key=lambda x: x[1])[0]  # Get the string with the highest score\n",
        "  else:\n",
        "    rep = \"\"  # If all tuples are empty, return an empty string\n",
        "  return str(rep)\n",
        "\n",
        "\n",
        "def get_variables(text):\n",
        "  matches = re.findall(r'\\[(.*?)\\]', text)\n",
        "  variables={}\n",
        "  wiki_searches=[]\n",
        "  errors=[]\n",
        "\n",
        "  def replace_variable(match):\n",
        "    #print(variables)\n",
        "    rep = variables.get(match.group(), match.group())\n",
        "    if isinstance(rep, list):\n",
        "        rep=process_list_tuple(rep)\n",
        "    return rep\n",
        "\n",
        "  for instruction in matches:\n",
        "    #print('at ', instruction)\n",
        "    #print(variables)\n",
        "    #---WIKI TOOL---\n",
        "    if(instruction.find(\"-Wiki\")!=-1):\n",
        "      query,ans=instruction.split(\"-Wiki->\") #for in query variables\n",
        "      query=query.strip()\n",
        "      ans=ans.strip()\n",
        "      in_query_var=re.search(r'y\\d+', query)\n",
        "      if(in_query_var):\n",
        "        #print(\"IN QUERY VAR\",query)\n",
        "        query=re.sub(r'y\\d+', replace_variable, query)\n",
        "        #print(query)\n",
        "      try:\n",
        "        title_score_dict,excerpt_text,full_content=wikipedia_seach(query)#wikipedia search\n",
        "        if title_score_dict:\n",
        "          #print('HERE updating varibale of wiki answer',ans.strip())\n",
        "          variables[ans.strip()] = [excerpt_text, full_content]#replaces the answer variable with extracted content\n",
        "          wiki_searches.append(title_score_dict)\n",
        "        else:\n",
        "          print('WIKI RESPONSE FAIL')\n",
        "          errors.append(f\"Error: Wikipedia search unsuccessful for query: '{query}'\")\n",
        "          break\n",
        "      except:\n",
        "        print('WIKI RESPONSE FAIL')\n",
        "        errors.append(f\"Error: Wikipedia search unsuccessful for query: '{query}'\")\n",
        "        break\n",
        "\n",
        "    #---QA TOOL---\n",
        "    if(instruction.find(\"-QA\")!=-1):\n",
        "      q,a=instruction.split(\"->\")\n",
        "      result = re.search(r'\\((.*?)\\)', q)\n",
        "      if result:\n",
        "          question = result.group(1)\n",
        "      else:\n",
        "          errors.append(\"Error in finding question\")\n",
        "          break\n",
        "\n",
        "      pre=q.split(\" -QA\")[0]\n",
        "      context_exc=\"\"\n",
        "      full_context=\"\"\n",
        "      if (pre.find(\"+\")!=-1): #if multiple contexts need to be appended\n",
        "\n",
        "        vars=pre.split(\"+\")\n",
        "        for i in vars:\n",
        "          if(i.strip() in variables.keys()):\n",
        "            if((str(type(variables[i.strip()][0]))!=\"<class 'tuple'>\")):\n",
        "              context_exc=variables[i.strip()][0] #if variable came from wiki search, it would be a string else it would be a tuple\n",
        "              full_context=variables[i.strip()][1]\n",
        "            else:\n",
        "              t=process_list_tuple(variables[i.strip()])\n",
        "              #print('-----t',t)\n",
        "              context_exc=t #if variable came from wiki search, it would be a string else it would be a tuple\n",
        "              full_context=t\n",
        "          else:\n",
        "            errors.append(f\"Error: Context variable '{i.strip()}' not found\")\n",
        "            break\n",
        "        if(context_exc==\"\"):\n",
        "          break\n",
        "\n",
        "      else: #single context QA\n",
        "        context_var=pre.strip()\n",
        "        if context_var in variables.keys():\n",
        "          if((str(type(variables[context_var][0]))!=\"<class 'tuple'>\")):\n",
        "            context_exc=variables[context_var][0] #if variable came from wiki search, it would be a string else it would be a tuple\n",
        "            full_context=variables[context_var][1]\n",
        "          else:\n",
        "            t=process_list_tuple(variables[context_var])\n",
        "            context_exc=t #if variable came from wiki search, it would be a string else it would be a tuple\n",
        "            full_context=t\n",
        "        else:\n",
        "          errors.append(f\"Error: Context variable '{context_var}' not found\")\n",
        "          break\n",
        "      \n",
        "      execerpt_run=QA(question, context_exc)\n",
        "      if(execerpt_run[-1]<0.75 and len(full_context)>0):\n",
        "        full_run=QA(question, full_context)\n",
        "      else:\n",
        "        full_run=()\n",
        "\n",
        "      #print('Updating variable',a.strip())\n",
        "      variables[a.strip()]=[execerpt_run,full_run]\n",
        "\n",
        "\n",
        "  return variables,wiki_searches,errors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##NEW\n",
        "def process_list_tuple(rep):\n",
        "  if(str(type(rep[0]))!=\"<class 'tuple'>\"): #if wikipedia article comes as in query, return empty string as it is anyways invalid\n",
        "    return \"\"\n",
        "  #for QA result, best score string returned\n",
        "  non_empty_rep = [item for item in rep if item]  # Filter out empty tuples\n",
        "  if non_empty_rep:\n",
        "    rep = max(non_empty_rep, key=lambda x: x[1])[0]  # Get the string with the highest score\n",
        "  else:\n",
        "    rep = \"\"  # If all tuples are empty, return an empty string\n",
        "  return str(rep)\n",
        "\n",
        "\n",
        "def get_variables(text):\n",
        "  matches = re.findall(r'\\[(.*?)\\]', text)\n",
        "  variables={}\n",
        "  wiki_searches=[]\n",
        "  errors=[]\n",
        "\n",
        "  def replace_variable(match):\n",
        "    #print(variables)\n",
        "    rep = variables.get(match.group(), match.group())\n",
        "    if isinstance(rep, list):\n",
        "        rep=process_list_tuple(rep)\n",
        "    return rep\n",
        "\n",
        "  for instruction in matches:\n",
        "\n",
        "    #print('at ', instruction)\n",
        "    #print(variables)\n",
        "    #---WIKI TOOL---\n",
        "    if(instruction.find(\"-Wiki\")!=-1):\n",
        "      try:\n",
        "        query,ans=instruction.split(\"-Wiki->\") #for in query variables\n",
        "        query=query.strip()\n",
        "        ans=ans.strip()\n",
        "        in_query_var=re.search(r'y\\d+', query)\n",
        "        if(in_query_var):\n",
        "          #print(\"IN QUERY VAR\",query)\n",
        "          query=re.sub(r'y\\d+', replace_variable, query)\n",
        "          #print(query)\n",
        "        \n",
        "        title_score_dict,excerpt_text,full_content=wikipedia_seach(query)#wikipedia search\n",
        "\n",
        "        if title_score_dict:\n",
        "          #print('HERE updating varibale of wiki answer',ans.strip())\n",
        "          variables[ans.strip()] = [excerpt_text, full_content]#replaces the answer variable with extracted content\n",
        "          wiki_searches.append(title_score_dict)\n",
        "        else:\n",
        "          errors.append(f\"Error: Wikipedia search unsuccessful for query: '{query}'\")\n",
        "          break\n",
        "      except:\n",
        "        errors.append(f\"Error: Wikipedia search unsuccessful for query: '{query}'\")\n",
        "        break\n",
        "\n",
        "    #---QA TOOL---\n",
        "    if(instruction.find(\"-QA\")!=-1):\n",
        "      q,a=instruction.split(\"->\")\n",
        "      result = re.search(r'\\((.*?)\\)', q)\n",
        "      if result:\n",
        "          question = result.group(1)\n",
        "      else:\n",
        "          errors.append(\"Error in finding question\")\n",
        "          break\n",
        "\n",
        "      pre=q.split(\" -QA\")[0]\n",
        "      context_exc=\"\"\n",
        "      full_context=\"\"\n",
        "      if (pre.find(\"+\")!=-1): #if multiple contexts need to be appended\n",
        "\n",
        "        vars=pre.split(\"+\")\n",
        "        for i in vars:\n",
        "          if(i.strip() in variables.keys()):\n",
        "            if((str(type(variables[i.strip()][0]))!=\"<class 'tuple'>\")):\n",
        "              context_exc=variables[i.strip()][0] #if variable came from wiki search, it would be a string else it would be a tuple\n",
        "              full_context=variables[i.strip()][1]\n",
        "            else:\n",
        "              t=process_list_tuple(variables[i.strip()])\n",
        "              #print('-----t',t)\n",
        "              context_exc=t #if variable came from wiki search, it would be a string else it would be a tuple\n",
        "              full_context=t\n",
        "          else:\n",
        "            errors.append(f\"Error: Context variable '{i.strip()}' not found\")\n",
        "            break\n",
        "        if(context_exc==\"\"):\n",
        "          break\n",
        "\n",
        "      else: #single context QA\n",
        "        context_var=pre.strip()\n",
        "        if context_var in variables.keys():\n",
        "          if((str(type(variables[context_var][0]))!=\"<class 'tuple'>\")):\n",
        "            context_exc=variables[context_var][0] #if variable came from wiki search, it would be a string else it would be a tuple\n",
        "            full_context=variables[context_var][1]\n",
        "          else:\n",
        "            t=process_list_tuple(variables[context_var])\n",
        "            context_exc=t #if variable came from wiki search, it would be a string else it would be a tuple\n",
        "            full_context=t\n",
        "        else:\n",
        "          errors.append(f\"Error: Context variable '{context_var}' not found\")\n",
        "          break\n",
        "      \n",
        "      execerpt_run=QA(question, context_exc)\n",
        "      if(execerpt_run[-1]<0.75 and len(full_context)>0):\n",
        "        full_run=QA(question, full_context)\n",
        "      else:\n",
        "        full_run=()\n",
        "\n",
        "      #print('Updating variable',a.strip())\n",
        "      variables[a.strip()]=[execerpt_run,full_run]\n",
        "\n",
        "\n",
        "  return variables,wiki_searches,errors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wluHd850lQmO"
      },
      "outputs": [],
      "source": [
        "# p=pd.read_pickle(\"processed_rows_wiki2.pkl\")\n",
        "# processed=p.to_dict(\"records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed=processed[:1179]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1179"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'httpCode': 429, 'httpReason': ''}\n",
            "WIKI RESPONSE FAIL\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['who does the character Milhouse get his name from -Wiki-> y1',\n",
              " 'y1 -QA(Milhouse Van Houten was named after who?)-> y2',\n",
              " 'Milhouse Van Houten -QA(Who is Milhouse Van Houten named after?)-> y3',\n",
              " 'y2 -QA(Who is y1?)-> y4']"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "row=2\n",
        "text=df.iloc[row]['C']\n",
        "matches = re.findall(r'\\[(.*?)\\]', text)\n",
        "v,w,e=get_variables(text)\n",
        "matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "NmA861q368EH"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>W</th>\n",
              "      <th>C</th>\n",
              "      <th>Variables</th>\n",
              "      <th>Wiki_Searches</th>\n",
              "      <th>Errors</th>\n",
              "      <th>Generated_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4875</th>\n",
              "      <td>What actress starred in Poor Pretty Eddie, and...</td>\n",
              "      <td>Leslie Uggams</td>\n",
              "      <td>Poor Pretty Eddie &gt; Poor Pretty Eddie is a 197...</td>\n",
              "      <td>First Search [What actress starred in Poor Pre...</td>\n",
              "      <td>{}</td>\n",
              "      <td>[]</td>\n",
              "      <td>[Error: Wikipedia search unsuccessful for quer...</td>\n",
              "      <td>not found</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4876</th>\n",
              "      <td>Mahatma Gandhi led India to independence throu...</td>\n",
              "      <td>obstructive program</td>\n",
              "      <td>Constructive Program &gt; Constructive Program (C...</td>\n",
              "      <td>First search [What Mahatma Gandhi led India to...</td>\n",
              "      <td>{}</td>\n",
              "      <td>[]</td>\n",
              "      <td>[Error: Wikipedia search unsuccessful for quer...</td>\n",
              "      <td>not found</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4877</th>\n",
              "      <td>The author of \"The Origins of Totalitarianism\"...</td>\n",
              "      <td>German-born</td>\n",
              "      <td>The Origins of Totalitarianism &gt; The Origins o...</td>\n",
              "      <td>First Search [Who was the author of \"The Origi...</td>\n",
              "      <td>{}</td>\n",
              "      <td>[]</td>\n",
              "      <td>[Error: Wikipedia search unsuccessful for quer...</td>\n",
              "      <td>not found</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4878</th>\n",
              "      <td>Who was the American actor who starred in \"Man...</td>\n",
              "      <td>Bruce Campbell</td>\n",
              "      <td>Maniac Cop &gt; Maniac Cop is a 1988 American act...</td>\n",
              "      <td>First Search [Who starred in \"Maniac Cop\" -Wik...</td>\n",
              "      <td>{}</td>\n",
              "      <td>[]</td>\n",
              "      <td>[Error: Wikipedia search unsuccessful for quer...</td>\n",
              "      <td>not found</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4879</th>\n",
              "      <td>The work of philosophy and social criticism kn...</td>\n",
              "      <td>society</td>\n",
              "      <td>Dialectic of Enlightenment &gt; Dialectic of Enli...</td>\n",
              "      <td>First search [Who was the author of \"Dialectic...</td>\n",
              "      <td>{}</td>\n",
              "      <td>[]</td>\n",
              "      <td>[Error: Wikipedia search unsuccessful for quer...</td>\n",
              "      <td>not found</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      Q                    A  \\\n",
              "4875  What actress starred in Poor Pretty Eddie, and...        Leslie Uggams   \n",
              "4876  Mahatma Gandhi led India to independence throu...  obstructive program   \n",
              "4877  The author of \"The Origins of Totalitarianism\"...          German-born   \n",
              "4878  Who was the American actor who starred in \"Man...       Bruce Campbell   \n",
              "4879  The work of philosophy and social criticism kn...              society   \n",
              "\n",
              "                                                      W  \\\n",
              "4875  Poor Pretty Eddie > Poor Pretty Eddie is a 197...   \n",
              "4876  Constructive Program > Constructive Program (C...   \n",
              "4877  The Origins of Totalitarianism > The Origins o...   \n",
              "4878  Maniac Cop > Maniac Cop is a 1988 American act...   \n",
              "4879  Dialectic of Enlightenment > Dialectic of Enli...   \n",
              "\n",
              "                                                      C Variables  \\\n",
              "4875  First Search [What actress starred in Poor Pre...        {}   \n",
              "4876  First search [What Mahatma Gandhi led India to...        {}   \n",
              "4877  First Search [Who was the author of \"The Origi...        {}   \n",
              "4878  First Search [Who starred in \"Maniac Cop\" -Wik...        {}   \n",
              "4879  First search [Who was the author of \"Dialectic...        {}   \n",
              "\n",
              "     Wiki_Searches                                             Errors  \\\n",
              "4875            []  [Error: Wikipedia search unsuccessful for quer...   \n",
              "4876            []  [Error: Wikipedia search unsuccessful for quer...   \n",
              "4877            []  [Error: Wikipedia search unsuccessful for quer...   \n",
              "4878            []  [Error: Wikipedia search unsuccessful for quer...   \n",
              "4879            []  [Error: Wikipedia search unsuccessful for quer...   \n",
              "\n",
              "     Generated_answer  \n",
              "4875        not found  \n",
              "4876        not found  \n",
              "4877        not found  \n",
              "4878        not found  \n",
              "4879        not found  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wi1FAZfwjPih"
      },
      "outputs": [],
      "source": [
        "processed_df=pd.read_pickle('/content/drive/MyDrive/NLP project/Wiki_tool/processed_rows_final_wiki2.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbsvW46-Ww0u"
      },
      "outputs": [],
      "source": [
        "processed_df.to_csv('a.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcbEutw1WwyM"
      },
      "outputs": [],
      "source": [
        "processed_df[240:260]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPba8C3qNkhr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eri_hhN_Nkfh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUWcQHc1Nkcp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrShiw8oO03g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE_pgMA0O0y0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWi55eEBO0uY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTO-7XwGWuFv"
      },
      "source": [
        "# EXPERIMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY9zW2B24IQD",
        "outputId": "6955842b-dca0-4ce1-91fb-2fdfec90f242"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['type of script used in autographs -Wiki-> y1',\n",
              " 'y1 -QA(What script was used in autographs?)-> y2',\n",
              " 'Cuneiform script invented by-Wiki-> y3',\n",
              " 'y3 -QA(Who invented cuneiform script?)-> y4']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "row=95\n",
        "text=df.iloc[row]['C']\n",
        "matches = re.findall(r'\\[(.*?)\\]', text)\n",
        "matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arvxBul74xBc",
        "outputId": "0b40f143-0a58-4afd-8957-cf84446b1ed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at isnt Henri Leconte Grand Slam titles  -Wiki-> y1\n",
            "at isnt Jonathan Stark Grand Slam titles  -Wiki-> y2\n",
            "at isnt y1+y2 -QA(Which tennis player won more Grand Slam titles, Henri Leconte or Jonathan Stark?)-> y3\n"
          ]
        }
      ],
      "source": [
        "def replace_variable(match):\n",
        "    return variables.get(match.group(), match.group())\n",
        "\n",
        "variables={}\n",
        "wiki_searches=[]\n",
        "for instruction in matches:\n",
        "  #print(\"at isnt\",instruction,)\n",
        "  if(instruction.find(\"-Wiki\")!=-1):\n",
        "    query,ans=instruction.split(\" -Wiki-> \")\n",
        "    #for in query variables\n",
        "    in_query_var=re.search(r'y\\d+', query)\n",
        "    if(in_query_var):\n",
        "      print(\"FOUND INQUERY VAR\")\n",
        "      query=re.sub(r'y\\d+', replace_variable, query)\n",
        "    #wikipedia search\n",
        "    title_score_dict,excerpt_text,full_content=wikipedia_seach(query)\n",
        "    #replaces the answer variable with extracted content\n",
        "    variables[ans.strip()]= [excerpt_text,full_content]\n",
        "    wiki_searches.append(title_score_dict)\n",
        "\n",
        "  if(instruction.find(\"-QA\")!=-1):\n",
        "    q,a=instruction.split(\"->\")\n",
        "    result = re.search(r'\\((.*?)\\)', text)\n",
        "    if result:\n",
        "        question = result.group(1)\n",
        "    else:\n",
        "        print(\"Error in finding question\")\n",
        "        continue\n",
        "\n",
        "    pre=q.split(\" -QA\")[0]\n",
        "    if (pre.find(\"+\")!=-1):\n",
        "      vars=pre.split(\"+\")\n",
        "      context_exc=\"\"\n",
        "      full_context=\"\"\n",
        "      for i in vars:\n",
        "        if(i.strip() in variables.keys()):\n",
        "          context_exc=context_exc+variables[i.strip()][0]\n",
        "          full_context=full_context+variables[i.strip()][1]\n",
        "        else:\n",
        "          print('error in finding context variable')\n",
        "          continue\n",
        "\n",
        "    else:\n",
        "      context_var=pre.strip()\n",
        "      if context_var in variables.keys():\n",
        "        context_exc=variables[context_var][0]\n",
        "        full_context=variables[context_var][1]\n",
        "      else:\n",
        "        print('error in finding context variable')\n",
        "        continue\n",
        "\n",
        "    execerpt_run=QA(question, context_exc)\n",
        "    if(execerpt_run[-1]<0.75):\n",
        "      full_run=QA(question, full_context)\n",
        "    else:\n",
        "      full_run=()\n",
        "    variables[a.strip()]=[execerpt_run,full_run]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK_mL1CEuMe3",
        "outputId": "55da98fd-769d-41f6-a34b-273e2fe02f69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'y1': [\"Henri Leconte Grand Slam titles : Noah to win the men's doubles title at the French Open in 1984. In 1985, Leconte and Noah reached a second Grand Slam doubles final at the US Open, where\\nThe Grand Slam Cup was a tennis tournament held annually at the Olympiahalle in Munich, Germany from 1990 through 1999. The event was organized by the\\nis the current era of professional tennis. It began in 1968 when the Grand Slam tournaments allowed professional players to compete with amateurs, ending\",\n",
              "  'Henri Leconte (born 4 July 1963) is a French former professional tennis player. He reached the men\\'s singles final at the French Open in 1988, won the French Open men\\'s doubles title in 1984, and helped France win the Davis Cup in 1991. Leconte\\'s career-high singles ranking was world No. 5.\\n\\n\\n== Biography and career ==\\nLeconte first came to the tennis world\\'s attention as an outstanding junior player who won the French Open junior title in 1981.  He turned professional that year and won his first career doubles title at Bologna, and his first top-level singles title the following year, 1982, in Stockholm. Leconte played in the Davis Cup final for the first time in 1982, when France was defeated 4–1 by the United States.\\nLeconte teamed up with Yannick Noah to win the men\\'s doubles title at the French Open in 1984. In 1985, Leconte and Noah reached a second Grand Slam doubles final at the US Open, where they finished runners-up. Leconte reached his career-high doubles ranking of world No. 6 in 1985. In singles in 1985, Leconte reached the quarterfinals of the French Open and Wimbledon, the latter run of which included a dazzling win over world no. 2, Ivan Lendl, in the fourth round.\\n1986 saw Leconte reach two Grand Slam singles semi-finals at the French Open and Wimbledon, and attain his career-high singles ranking of world No. 5. Leconte also played on the French team that won the World Team Cup that year.\\nIn 1988, Leconte reached the men\\'s singles final at the French Open beating Simon Youl, Bruno Orešar, Horacio de la Peña, Boris Becker, Andrei Chesnokov and Jonas Svensson. In the final, despite strong support from the French crowd, Leconte could not overcome two-time former champion Mats Wilander who defeated him in straight sets.\\nIn 1991, Leconte was involved in the Davis Cup final for a second time. France again faced the US, and this time Leconte defeated Pete Sampras in straight sets in a critical singles rubber, and also teamed with Guy Forget to win the doubles rubber, as France upset the heavily favoured U.S. team 3–1.\\nIn total, Leconte played for France\\'s Davis Cup team for a total of 13 consecutive years, compiling a 41–25 record. He compiled a doubles record of 17–5 and was undefeated with Guy Forget (11 wins), winning his last 14 doubles matches (from March 1985 to July 1993).\\nLeconte won his final top-level singles title in 1993 in Halle. He also won his final doubles title that year at Indian Wells.\\nLeconte retired from the professional tour in 1996, having won a total of nine career singles titles and ten doubles titles. Playing on the ATP Champions Tour for over-35\\'s, he formed a doubles partnership with the Iranian player Mansour Bahrami.\\nHe is now the manager of an event company (HL Event) based in Belgium and opened a tennis academy in Fès, Morocco, in 2006.\\nSince 2010, Leconte has appeared on Australian television as a commentator on the Seven Network\\'s coverage of the Australian Open. There, he obtained a cult following as a result of a zany exhibition doubles performance, and his passionate and often parochial commentary, especially for compatriot Jo-Wilfried Tsonga, whose winning shots he routinely described as \"unbelievable!\"\\nIn 2014, Leconte appeared as a commentator for the 2014 Australian Open. One match he commentated was the third-round match between Frenchmen Gilles Simon and Jo-Wilfried Tsonga. He has since appeared regularly as a commentator for matches involving French players in the men\\'s draw.\\n\\n\\n== Grand Slam singles performance timeline ==\\n\\n\\n== Trivia ==\\nHe participated in 2005 in the second season of La Ferme Célébrités, a TV reality game show. In 2007, his son Maxime also participated in the TV reality game show Secret Story, the French version of Big Brother.\\nHe also appeared as a contestant on BBC Celebrity Masterchef 2017, reaching the semifinals.\\n\\n\\n== Major finals ==\\n\\n\\n=== Grand Slam finals ===\\n\\n\\n==== Singles: 1 (0–1) ====\\n\\n\\n==== Doubles: 2 (1–1) ====\\n\\n\\n=== Masters Series finals ===\\n\\n\\n==== Doubles: 2 (1–1) ====\\n\\n\\n== Career finals ==\\n\\n\\n=== Singles: 16 (9–7) ===\\n\\n\\n=== Doubles: 19 (10–9) ===\\n\\n\\n== References ==\\n\\n\\n== External links ==\\n\\nHenri Leconte at the Association of Tennis Professionals \\nHenri Leconte at the International Tennis Federation \\nHenri Leconte at the Davis Cup \\nH Talent Management Henri Leconte client biography'],\n",
              " 'y2': ['Jonathan Stark Grand Slam titles : Jonathan Stark (born April 3, 1971) is a former professional tennis player from the United States. During his career he won two Grand Slam doubles titles\\nCareer Grand Slam and a non-calendar year Grand Slam (known as a \"Serena Slam\"). The next few years saw her capture two more major singles titles, but suffer\\nor more Grand Slam titles are included here. Active teams and tournament records indicated in bold. Teams with four or more Grand Slam titles are included',\n",
              "  \"Jonathan Stark (born April 3, 1971) is a former professional tennis player from the United States. During his career he won two Grand Slam doubles titles (the 1994 French Open Men's Doubles and the 1995 Wimbledon Championships Mixed Doubles). Stark reached the world No. 1 doubles ranking in 1994.\\n\\n\\n== Early life ==\\nStark was born in Medford, Oregon. He reached the finals of the 1989 Boys' Junior National Tennis Championship Boys' 18 singles, losing to Chuck Adams. In college, he played for Stanford University, where he was a singles and doubles All-American in 1990 and 1991. He reached the NCAA doubles final in 1991, partnering Jared Palmer. On July 17, 1997, he married Dana, and they have two sons and a daughter. He was coached by Donald Bozarth and became one of the top juniors.\\n\\n\\n== Professional tennis ==\\nStark turned professional in 1991 and joined the ATP Tour. In 1992, he won his first tour doubles title at Wellington. His first top-level singles title came in 1993 at Bolzano (beating Cédric Pioline in the final).\\nIn 1994, Stark captured the men's doubles title at the French Open, partnering Byron Black (the pair were also runners-up at the Australian Open that year).  He reached his career-high singles ranking of World No. 36 in February.  The following year, Stark won the Wimbledon mixed doubles title, partnering Martina Navratilova.\\nStark won his second top-level singles title in 1996 at Singapore (beating Michael Chang in the final). He was a member of the 1997 U.S. Davis Cup team. In 1997, Stark won the doubles title at the ATP Tour World Championships, partnering Rick Leach. The final doubles title of Stark's career came in 2001 at Long Island.\\nOver the course of his career, Stark won two top-level singles titles and 19 tour doubles titles. His career prize-money totaled US$3,220,867. Stark retired from the professional tour in 2001, lives in Portland, Oregon, and coaches with Portland-based Oregon Elite Tennis. He was inducted into the Oregon Sports Hall of Fame in 2009.\\n\\n\\n== Junior Grand Slam finals ==\\n\\n\\n=== Singles: 1 (1 title) ===\\n\\n\\n=== Doubles: 3 (3 titles) ===\\n\\n\\n== ATP career finals ==\\n\\n\\n=== Singles: 3 (2 titles, 1 runner-up) ===\\n\\n\\n=== Doubles: 40 (19 titles – 21 runners-up) ===\\n\\n\\n=== Runners-up (21) ===\\n\\n\\n==== Mixed doubles: 1 (1-0) ====\\n\\n\\n== ATP Challenger and ITF Futures Finals ==\\n\\n\\n=== Singles: 2 (2–0) ===\\n\\n\\n=== Doubles: 3 (2–1) ===\\n\\n\\n== Performance timelines ==\\n\\n\\n=== Singles ===\\n\\n\\n=== Doubles ===\\n\\n\\n=== Mixed doubles ===\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nJonathan Stark at the Association of Tennis Professionals\\nJonathan Stark at the International Tennis Federation \\nJonathan Stark at the Davis Cup\"],\n",
              " 'y3': [('endingJonathan Stark', 0.5225683450698853),\n",
              "  ('Henri Leconte', 0.35192638635635376)]}"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIta5rcwo-Sg",
        "outputId": "ecdc5b7c-1e27-4493-88bf-3fd8f330477b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'Henri Leconte': 0.6307155,\n",
              "  'Grand Slam Cup': 0.3890447,\n",
              "  \"Open Era tennis records – Men's singles\": 0.378835},\n",
              " {'Jonathan Stark (tennis)': 0.7212882,\n",
              "  'Serena Williams': 0.47569674,\n",
              "  \"List of Grand Slam men's doubles champions\": 0.4702412}]"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki_searches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3ME1-jFtAfA",
        "outputId": "0add0a03-6830-4327-be4c-36e9dc5b3c2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Jonathan Stark (tennis)', 'Jonathan Stark (tennis)', 'Henri Leconte']"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "true_wiki_pages=[i.split(\">\")[0].strip() for i in df.iloc[5]['W'].split(\"|\")]\n",
        "true_wiki_pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Vqlfwj7XAJW",
        "outputId": "4e32bffc-2152-4ad5-d2f6-db78978e6f19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37402\n"
          ]
        }
      ],
      "source": [
        "query=\"Number of legs in chicken\"\n",
        "t,e,f=wikipedia_seach(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOmZKXw9WCaU"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qm0WiZRvz5fd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vd3n3OKpz5dY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39PRz7sa1yhx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE936kuW1yfu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xdq5KVtz1rOY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bezt9Qvo1t9A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "V-Gy0GP9kJHi",
        "utVCim1vmYDU"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
